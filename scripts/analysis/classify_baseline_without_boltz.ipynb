{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "68111fad",
   "metadata": {},
   "source": [
    "This script takes the baseline model (without Boltz) and builds a classifier to predict a positive or negative pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0fa1b288",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import esm\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import Tensor\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR, LambdaLR\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.amp import autocast\n",
    "from torch.cuda.amp import GradScaler\n",
    "import copy\n",
    "from datetime import datetime\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "import math\n",
    "import random\n",
    "import pickle\n",
    "import subprocess\n",
    "import gc\n",
    "from pathlib import Path\n",
    "from typing import List, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "from IPython.display import display, update_display\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# ESM imports\n",
    "from esm.models.esmc import ESMC\n",
    "from esm.sdk.api import ESMProtein, LogitsConfig, ESMProteinTensor\n",
    "from esm.models.esmc import _BatchedESMProteinTensor\n",
    "\n",
    "# Tokenizer imports\n",
    "from tokenizers import Tokenizer\n",
    "from tokenizers.models import WordPiece\n",
    "from tokenizers import normalizers\n",
    "from tokenizers.normalizers import NFD, Lowercase, StripAccents\n",
    "from tokenizers.pre_tokenizers import Whitespace\n",
    "from tokenizers.trainers import WordPieceTrainer\n",
    "from tokenizers import decoders\n",
    "\n",
    "# PEFT imports\n",
    "from peft import get_peft_model, LoraConfig, TaskType\n",
    "from peft.tuners.lora import LoraConfig, LoraModel\n",
    "\n",
    "# Set environment variable\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c2b0e52",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tcr-multimodal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
