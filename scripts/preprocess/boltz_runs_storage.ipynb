{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4581201",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import subprocess, shlex\n",
    "import pandas as pd\n",
    "\n",
    "# === Configure paths ===\n",
    "BASE_DIR = Path(\"/home/natasha/multimodal_model\")\n",
    "\n",
    "RUN_ROOT = BASE_DIR / \"outputs\"\n",
    "RUN_ROOT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "BOLTZ_OUT_TRAIN = RUN_ROOT / \"train\"\n",
    "BOLTZ_OUT_VAL   = RUN_ROOT / \"val\"\n",
    "BOLTZ_OUT_TEST  = RUN_ROOT / \"test\"\n",
    "BOLTZ_OUT_TRAIN.mkdir(parents=True, exist_ok=True)\n",
    "BOLTZ_OUT_VAL.mkdir(parents=True, exist_ok=True)\n",
    "BOLTZ_OUT_TEST.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "YAML_DIR_TRAIN = BASE_DIR / \"data\" / \"train\"\n",
    "YAML_DIR_VAL   = BASE_DIR / \"data\" / \"val\"\n",
    "YAML_DIR_TEST  = BASE_DIR / \"data\" / \"test\"\n",
    "\n",
    "# Where your chunks live (created by your chunking helper)\n",
    "TRAIN_CHUNKS_ROOT = YAML_DIR_TRAIN / \"_chunks\"\n",
    "TEST_CHUNKS_ROOT  = YAML_DIR_TEST / \"_chunks\"\n",
    "\n",
    "# One GPU => run chunks sequentially\n",
    "NPROC = 1\n",
    "\n",
    "BOLTZ_CMD_TEMPLATE = (\n",
    "    \"conda run -n boltz-env --no-capture-output boltz predict {input_path} \"\n",
    "    \"--out_dir {outdir} \"\n",
    "    \"--accelerator gpu \"\n",
    "    \"--devices 1 \"\n",
    "    \"--model boltz2 \"\n",
    "    \"--recycling_steps 1 \"\n",
    "    \"--sampling_steps 10 \"\n",
    "    \"--diffusion_samples 1 \"\n",
    "    \"--max_parallel_samples 1 \"\n",
    "    \"--max_msa_seqs 64 \"\n",
    "    \"--num_subsampled_msa 34 \"\n",
    "    # IMPORTANT: remove --override once you're in production/resume mode\n",
    "    \"--write_embeddings\"\n",
    ")\n",
    "\n",
    "# --override (only use when want to rerun on all values)\n",
    "# also reduced num sampled msa to 34 and also number of recycling steps to 10 (from 20), to try and speed things up\n",
    "\n",
    "def run_cli(input_path: Path, outdir: Path) -> int:\n",
    "    \"\"\"\n",
    "    input_path can be:\n",
    "      - a single YAML file, or\n",
    "      - a directory containing many YAMLs (chunk)\n",
    "    \"\"\"\n",
    "    input_path = Path(input_path).resolve()\n",
    "    outdir = Path(outdir).resolve()\n",
    "    outdir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    cmd = BOLTZ_CMD_TEMPLATE.format(input_path=str(input_path), outdir=str(outdir))\n",
    "    print(\"CMD:\", cmd)\n",
    "\n",
    "    with open(outdir / \"stdout.log\", \"w\") as so, open(outdir / \"stderr.log\", \"w\") as se:\n",
    "        proc = subprocess.run(\n",
    "            shlex.split(cmd),\n",
    "            stdout=so,\n",
    "            stderr=se,\n",
    "            text=True,\n",
    "            cwd=str(BASE_DIR),\n",
    "        )\n",
    "\n",
    "    print(\"Return code:\", proc.returncode)\n",
    "    return proc.returncode\n",
    "\n",
    "\n",
    "def has_any_embeddings(outdir: Path) -> bool:\n",
    "    pred = Path(outdir) / \"predictions\"\n",
    "    if not pred.exists():\n",
    "        return False\n",
    "    return any(pred.rglob(\"embeddings_pair_*.npz\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d380184",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== TRAIN chunk_000 ===\n",
      "CMD: conda run -n boltz-env --no-capture-output boltz predict /home/natasha/multimodal_model/data/train/_chunks/chunk_000 --out_dir /data_ssd/boltz_outputs/train/chunk_000 --accelerator gpu --devices 1 --model boltz2 --recycling_steps 1 --sampling_steps 10 --diffusion_samples 1 --max_parallel_samples 1 --max_msa_seqs 64 --num_subsampled_msa 34 --write_embeddings\n",
      "Return code: 1\n",
      "[STOP] Train chunk failed: chunk_000. See logs in /home/natasha/multimodal_model/outputs/train/chunk_000\n"
     ]
    }
   ],
   "source": [
    "# RUN TRAIN CHUNKS\n",
    "\n",
    "def list_chunk_dirs(chunks_root: Path):\n",
    "    chunks_root = Path(chunks_root).resolve()\n",
    "    if not chunks_root.exists():\n",
    "        raise FileNotFoundError(f\"Chunks root not found: {chunks_root}\")\n",
    "\n",
    "    # chunk_000, chunk_001, ...\n",
    "    chunk_dirs = sorted([p for p in chunks_root.iterdir() if p.is_dir()])\n",
    "    if not chunk_dirs:\n",
    "        raise ValueError(f\"No chunk directories found in: {chunks_root}\")\n",
    "    return chunk_dirs\n",
    "\n",
    "train_chunk_dirs = list_chunk_dirs(TRAIN_CHUNKS_ROOT)\n",
    "\n",
    "for chunk_dir in train_chunk_dirs:\n",
    "    chunk_name = chunk_dir.name\n",
    "    outdir = BOLTZ_OUT_TRAIN / chunk_name\n",
    "    print(f\"\\n=== TRAIN {chunk_name} ===\")\n",
    "    rc = run_cli(chunk_dir, outdir)\n",
    "    if rc != 0:\n",
    "        print(f\"[STOP] Train chunk failed: {chunk_name}. See logs in {outdir}\")\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ee95582",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN TEST CHUNKS\n",
    "\n",
    "test_chunk_dirs = list_chunk_dirs(TEST_CHUNKS_ROOT)\n",
    "\n",
    "for chunk_dir in test_chunk_dirs:\n",
    "    chunk_name = chunk_dir.name\n",
    "    outdir = BOLTZ_OUT_TEST / chunk_name\n",
    "    print(f\"\\n=== TEST {chunk_name} ===\")\n",
    "    rc = run_cli(chunk_dir, outdir)\n",
    "    if rc != 0:\n",
    "        print(f\"[STOP] Test chunk failed: {chunk_name}. See logs in {outdir}\")\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fed902d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN VAL CHUNK\n",
    "\n",
    "print(\"\\n=== VAL (single directory) ===\")\n",
    "rc = run_cli(YAML_DIR_VAL, BOLTZ_OUT_VAL / \"val_all\")\n",
    "if rc != 0:\n",
    "    print(f\"[FAIL] Val run failed. See logs in {BOLTZ_OUT_VAL / 'val_all'}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb2633ec",
   "metadata": {},
   "source": [
    "Run With Resume from Chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f90a024f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pathlib import Path\n",
    "# import subprocess, shlex, time\n",
    "\n",
    "# BASE_DIR = Path(\"/home/natasha/multimodal_model\")\n",
    "\n",
    "# # outputs is a symlink -> /data_ssd/boltz_outputs (good)\n",
    "# RUN_ROOT = BASE_DIR / \"outputs\"\n",
    "# RUN_ROOT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# BOLTZ_OUT_TRAIN = RUN_ROOT / \"train\"\n",
    "# BOLTZ_OUT_VAL   = RUN_ROOT / \"val\"\n",
    "# BOLTZ_OUT_TEST  = RUN_ROOT / \"test\"\n",
    "# for p in (BOLTZ_OUT_TRAIN, BOLTZ_OUT_VAL, BOLTZ_OUT_TEST):\n",
    "#     p.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# YAML_DIR_TRAIN = BASE_DIR / \"data\" / \"train\"\n",
    "# YAML_DIR_VAL   = BASE_DIR / \"data\" / \"val\"\n",
    "# YAML_DIR_TEST  = BASE_DIR / \"data\" / \"test\"\n",
    "\n",
    "# TRAIN_CHUNKS_ROOT = YAML_DIR_TRAIN / \"_chunks\"\n",
    "# TEST_CHUNKS_ROOT  = YAML_DIR_TEST  / \"_chunks\"\n",
    "\n",
    "# BOLTZ_CMD_TEMPLATE = (\n",
    "#     \"conda run -n boltz-env --no-capture-output boltz predict {input_path} \"\n",
    "#     \"--out_dir {outdir} \"\n",
    "#     \"--accelerator gpu \"\n",
    "#     \"--devices 1 \"\n",
    "#     \"--model boltz2 \"\n",
    "#     \"--recycling_steps 1 \"\n",
    "#     \"--sampling_steps 10 \"\n",
    "#     \"--diffusion_samples 1 \"\n",
    "#     \"--max_parallel_samples 1 \"\n",
    "#     \"--max_msa_seqs 64 \"\n",
    "#     \"--num_subsampled_msa 34 \"\n",
    "#     \"--write_embeddings\"\n",
    "# )\n",
    "\n",
    "# DONE_MARKER = \".DONE\"\n",
    "# FAIL_LOG = \"failed_yamls.txt\"     # append-only\n",
    "# STAMP = lambda: time.strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "\n",
    "# def run_cli(input_path: Path, outdir: Path) -> int:\n",
    "#     input_path = Path(input_path).resolve()\n",
    "#     outdir = Path(outdir).resolve()\n",
    "#     outdir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "#     cmd = BOLTZ_CMD_TEMPLATE.format(input_path=str(input_path), outdir=str(outdir))\n",
    "#     so_path = outdir / f\"stdout_{STAMP()}.log\"\n",
    "#     se_path = outdir / f\"stderr_{STAMP()}.log\"\n",
    "\n",
    "#     print(\"CMD:\", cmd)\n",
    "#     with open(so_path, \"w\") as so, open(se_path, \"w\") as se:\n",
    "#         proc = subprocess.run(\n",
    "#             shlex.split(cmd),\n",
    "#             stdout=so,\n",
    "#             stderr=se,\n",
    "#             text=True,\n",
    "#             cwd=str(BASE_DIR),\n",
    "#         )\n",
    "#     print(\"Return code:\", proc.returncode)\n",
    "#     return proc.returncode\n",
    "\n",
    "\n",
    "# def list_chunk_dirs(chunks_root: Path):\n",
    "#     chunks_root = Path(chunks_root).resolve()\n",
    "#     if not chunks_root.exists():\n",
    "#         raise FileNotFoundError(f\"Chunks root not found: {chunks_root}\")\n",
    "#     chunk_dirs = sorted([p for p in chunks_root.iterdir() if p.is_dir() and p.name.startswith(\"chunk_\")])\n",
    "#     if not chunk_dirs:\n",
    "#         raise ValueError(f\"No chunk directories found in: {chunks_root}\")\n",
    "#     return chunk_dirs\n",
    "\n",
    "\n",
    "# def list_yamls(dir_path: Path):\n",
    "#     d = Path(dir_path)\n",
    "#     return sorted(list(d.glob(\"*.yml\")) + list(d.glob(\"*.yaml\")))\n",
    "\n",
    "\n",
    "# def yaml_to_pair_dirname(yaml_path: Path) -> str:\n",
    "#     \"\"\"\n",
    "#     Assumption that matches your structure: pair_000.yaml -> pair_000\n",
    "#     If your YAMLs are named differently, tweak this one function only.\n",
    "#     \"\"\"\n",
    "#     return yaml_path.stem\n",
    "\n",
    "\n",
    "# def embeddings_exist_for_yaml(yaml_path: Path, outdir: Path) -> bool:\n",
    "#     pair_dir = Path(outdir) / \"predictions\" / yaml_to_pair_dirname(yaml_path)\n",
    "#     return any(pair_dir.glob(\"embeddings_pair_*.npz\"))\n",
    "\n",
    "\n",
    "# def all_embeddings_exist_for_dir(input_dir: Path, outdir: Path) -> bool:\n",
    "#     yamls = list_yamls(input_dir)\n",
    "#     if not yamls:\n",
    "#         return False\n",
    "#     return all(embeddings_exist_for_yaml(y, outdir) for y in yamls)\n",
    "\n",
    "\n",
    "# def mark_done(outdir: Path):\n",
    "#     (Path(outdir) / DONE_MARKER).write_text(f\"done_at={time.strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n",
    "\n",
    "\n",
    "# def append_fail(outdir: Path, yaml_path: Path, rc: int):\n",
    "#     p = Path(outdir) / FAIL_LOG\n",
    "#     with open(p, \"a\") as f:\n",
    "#         f.write(f\"{time.strftime('%Y-%m-%d %H:%M:%S')}\\trc={rc}\\t{yaml_path}\\n\")\n",
    "\n",
    "\n",
    "# def run_dir_with_safe_resume(input_dir: Path, outdir: Path, label: str):\n",
    "#     \"\"\"\n",
    "#     Runs a chunk/val dir with:\n",
    "#       - hard skip if DONE exists\n",
    "#       - hard skip if all embeddings already present\n",
    "#       - attempt fast directory run\n",
    "#       - on failure, fall back to per-YAML runs with per-YAML skip\n",
    "#       - continue past failures, record them, do not overwrite existing embeddings\n",
    "#     \"\"\"\n",
    "#     input_dir = Path(input_dir)\n",
    "#     outdir = Path(outdir)\n",
    "\n",
    "#     if (outdir / DONE_MARKER).exists():\n",
    "#         print(f\"[SKIP] {label} already has {DONE_MARKER}: {outdir}\")\n",
    "#         return\n",
    "\n",
    "#     if all_embeddings_exist_for_dir(input_dir, outdir):\n",
    "#         print(f\"[SKIP] {label} already complete by embeddings check: {outdir}\")\n",
    "#         mark_done(outdir)\n",
    "#         return\n",
    "\n",
    "#     # 1) Try the fast path: run boltz on the directory\n",
    "#     print(f\"\\n=== {label} (dir run) ===\")\n",
    "#     rc = run_cli(input_dir, outdir)\n",
    "\n",
    "#     if rc == 0 and all_embeddings_exist_for_dir(input_dir, outdir):\n",
    "#         mark_done(outdir)\n",
    "#         return\n",
    "\n",
    "#     # 2) Fallback: per-YAML safe resume (skip if embeddings exist)\n",
    "#     print(f\"[FALLBACK] {label}: switching to per-YAML runs (safe resume).\")\n",
    "#     yamls = list_yamls(input_dir)\n",
    "#     for y in yamls:\n",
    "#         if embeddings_exist_for_yaml(y, outdir):\n",
    "#             print(f\"[SKIP-YAML] embeddings exist: {y.name}\")\n",
    "#             continue\n",
    "\n",
    "#         rc_y = run_cli(y, outdir)\n",
    "#         if rc_y != 0:\n",
    "#             print(f\"[FAIL-YAML] {y.name} (rc={rc_y}) — logged, continuing.\")\n",
    "#             append_fail(outdir, y, rc_y)\n",
    "#             continue\n",
    "\n",
    "#         # After successful run, ensure embeddings exist; if not, log it\n",
    "#         if not embeddings_exist_for_yaml(y, outdir):\n",
    "#             print(f\"[WARN] {y.name} returned 0 but embeddings not found — logged.\")\n",
    "#             append_fail(outdir, y, 999)\n",
    "\n",
    "#     # Done if all embeddings exist for all yamls (ignoring failures)\n",
    "#     if all_embeddings_exist_for_dir(input_dir, outdir):\n",
    "#         mark_done(outdir)\n",
    "#     else:\n",
    "#         print(f\"[INFO] {label} not fully complete; check {outdir}/{FAIL_LOG} and rerun later.\")\n",
    "\n",
    "\n",
    "# def run_chunked_dataset(chunks_root: Path, out_root: Path, label: str):\n",
    "#     for chunk_dir in list_chunk_dirs(chunks_root):\n",
    "#         outdir = Path(out_root) / chunk_dir.name\n",
    "#         run_dir_with_safe_resume(chunk_dir, outdir, f\"{label} {chunk_dir.name}\")\n",
    "\n",
    "\n",
    "# def run_val_folder(val_yaml_dir: Path, out_root: Path):\n",
    "#     outdir = Path(out_root) / \"val_full\"\n",
    "#     run_dir_with_safe_resume(Path(val_yaml_dir), outdir, \"VAL val_full\")\n",
    "\n",
    "\n",
    "# # ---- Execute ----\n",
    "# run_chunked_dataset(TRAIN_CHUNKS_ROOT, BOLTZ_OUT_TRAIN, \"TRAIN\")\n",
    "# run_val_folder(YAML_DIR_VAL, BOLTZ_OUT_VAL)\n",
    "# run_chunked_dataset(TEST_CHUNKS_ROOT, BOLTZ_OUT_TEST, \"TEST\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb892b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import subprocess, time, shlex, os\n",
    "\n",
    "BASE_DIR = Path(\"/home/natasha/multimodal_model\")\n",
    "\n",
    "# outputs is a symlink -> /data_ssd/boltz_outputs (good)\n",
    "RUN_ROOT = BASE_DIR / \"outputs\"\n",
    "RUN_ROOT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "BOLTZ_OUT_TRAIN = RUN_ROOT / \"train\"\n",
    "BOLTZ_OUT_VAL   = RUN_ROOT / \"val\"\n",
    "BOLTZ_OUT_TEST  = RUN_ROOT / \"test\"\n",
    "for p in (BOLTZ_OUT_TRAIN, BOLTZ_OUT_VAL, BOLTZ_OUT_TEST):\n",
    "    p.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "YAML_DIR_TRAIN = BASE_DIR / \"data\" / \"train\"\n",
    "YAML_DIR_VAL   = BASE_DIR / \"data\" / \"val\"\n",
    "YAML_DIR_TEST  = BASE_DIR / \"data\" / \"test\"\n",
    "\n",
    "TRAIN_CHUNKS_ROOT = YAML_DIR_TRAIN / \"_chunks\"\n",
    "TEST_CHUNKS_ROOT  = YAML_DIR_TEST  / \"_chunks\"\n",
    "\n",
    "# ---- LOCKED ENV ----\n",
    "BOLTZ_ENV = \"boltz-env-torchfix\"\n",
    "CONDA_BASE = Path(\"/home/natasha/miniconda3\")  # adjust if yours differs\n",
    "CONDA_SH = CONDA_BASE / \"etc\" / \"profile.d\" / \"conda.sh\"\n",
    "\n",
    "# kernels ON => do NOT pass --no_kernels\n",
    "# If you want production settings, tweak sampling/recycling here.\n",
    "BOLTZ_ARGS = (\n",
    "    \"--accelerator gpu \"\n",
    "    \"--devices 1 \"\n",
    "    \"--model boltz2 \"\n",
    "    \"--recycling_steps 1 \"\n",
    "    \"--sampling_steps 10 \"\n",
    "    \"--diffusion_samples 1 \"\n",
    "    \"--max_parallel_samples 1 \"\n",
    "    \"--max_msa_seqs 64 \"\n",
    "    \"--num_subsampled_msa 34 \"\n",
    "    \"--write_embeddings\"\n",
    ")\n",
    "\n",
    "DONE_MARKER = \".DONE\"\n",
    "FAIL_LOG = \"failed_yamls.txt\"     # append-only\n",
    "STAMP = lambda: time.strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "\n",
    "def build_boltz_command(input_path: Path, outdir: Path) -> list[str]:\n",
    "    \"\"\"\n",
    "    Runs boltz inside a real 'conda activate' so activate.d hooks apply.\n",
    "    This is the most reliable way to ensure your LD_PRELOAD/LD_LIBRARY_PATH fix is used.\n",
    "    \"\"\"\n",
    "    input_q = shlex.quote(str(Path(input_path).resolve()))\n",
    "    outdir_q = shlex.quote(str(Path(outdir).resolve()))\n",
    "\n",
    "    # shell snippet: source conda.sh -> conda activate -> boltz predict ...\n",
    "    shell_cmd = (\n",
    "        f\"source {shlex.quote(str(CONDA_SH))} && \"\n",
    "        f\"conda activate {shlex.quote(BOLTZ_ENV)} && \"\n",
    "        f\"boltz predict {input_q} --out_dir {outdir_q} {BOLTZ_ARGS}\"\n",
    "    )\n",
    "\n",
    "    # Run via bash -lc so conda activation behaves properly\n",
    "    return [\"bash\", \"-lc\", shell_cmd]\n",
    "\n",
    "\n",
    "def run_cli(input_path: Path, outdir: Path) -> int:\n",
    "    input_path = Path(input_path).resolve()\n",
    "    outdir = Path(outdir).resolve()\n",
    "    outdir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    cmd_list = build_boltz_command(input_path, outdir)\n",
    "\n",
    "    so_path = outdir / f\"stdout_{STAMP()}.log\"\n",
    "    se_path = outdir / f\"stderr_{STAMP()}.log\"\n",
    "\n",
    "    print(\"CMD:\", \" \".join(cmd_list))\n",
    "    with open(so_path, \"w\") as so, open(se_path, \"w\") as se:\n",
    "        proc = subprocess.run(\n",
    "            cmd_list,\n",
    "            stdout=so,\n",
    "            stderr=se,\n",
    "            text=True,\n",
    "            cwd=str(BASE_DIR),\n",
    "        )\n",
    "    print(\"Return code:\", proc.returncode)\n",
    "    return proc.returncode\n",
    "\n",
    "\n",
    "def list_chunk_dirs(chunks_root: Path):\n",
    "    chunks_root = Path(chunks_root).resolve()\n",
    "    if not chunks_root.exists():\n",
    "        raise FileNotFoundError(f\"Chunks root not found: {chunks_root}\")\n",
    "    chunk_dirs = sorted([p for p in chunks_root.iterdir() if p.is_dir() and p.name.startswith(\"chunk_\")])\n",
    "    if not chunk_dirs:\n",
    "        raise ValueError(f\"No chunk directories found in: {chunks_root}\")\n",
    "    return chunk_dirs\n",
    "\n",
    "\n",
    "def list_yamls(dir_path: Path):\n",
    "    d = Path(dir_path)\n",
    "    return sorted(list(d.glob(\"*.yml\")) + list(d.glob(\"*.yaml\")))\n",
    "\n",
    "\n",
    "def yaml_to_pair_dirname(yaml_path: Path) -> str:\n",
    "    return yaml_path.stem\n",
    "\n",
    "\n",
    "def embeddings_exist_for_yaml(yaml_path: Path, outdir: Path) -> bool:\n",
    "    pair_dir = Path(outdir) / \"predictions\" / yaml_to_pair_dirname(yaml_path)\n",
    "    return any(pair_dir.glob(\"embeddings_pair_*.npz\"))\n",
    "\n",
    "\n",
    "def all_embeddings_exist_for_dir(input_dir: Path, outdir: Path) -> bool:\n",
    "    yamls = list_yamls(input_dir)\n",
    "    if not yamls:\n",
    "        return False\n",
    "    return all(embeddings_exist_for_yaml(y, outdir) for y in yamls)\n",
    "\n",
    "\n",
    "def mark_done(outdir: Path):\n",
    "    (Path(outdir) / DONE_MARKER).write_text(f\"done_at={time.strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n",
    "\n",
    "\n",
    "def append_fail(outdir: Path, yaml_path: Path, rc: int):\n",
    "    p = Path(outdir) / FAIL_LOG\n",
    "    with open(p, \"a\") as f:\n",
    "        f.write(f\"{time.strftime('%Y-%m-%d %H:%M:%S')}\\trc={rc}\\t{yaml_path}\\n\")\n",
    "\n",
    "\n",
    "def run_dir_with_safe_resume(input_dir: Path, outdir: Path, label: str):\n",
    "    input_dir = Path(input_dir)\n",
    "    outdir = Path(outdir)\n",
    "\n",
    "    if (outdir / DONE_MARKER).exists():\n",
    "        print(f\"[SKIP] {label} already has {DONE_MARKER}: {outdir}\")\n",
    "        return\n",
    "\n",
    "    if all_embeddings_exist_for_dir(input_dir, outdir):\n",
    "        print(f\"[SKIP] {label} already complete by embeddings check: {outdir}\")\n",
    "        mark_done(outdir)\n",
    "        return\n",
    "\n",
    "    # 1) Try fast path: run boltz on the directory\n",
    "    print(f\"\\n=== {label} (dir run) ===\")\n",
    "    rc = run_cli(input_dir, outdir)\n",
    "\n",
    "    if rc == 0 and all_embeddings_exist_for_dir(input_dir, outdir):\n",
    "        mark_done(outdir)\n",
    "        return\n",
    "\n",
    "    # 2) Fallback: per-YAML safe resume\n",
    "    print(f\"[FALLBACK] {label}: switching to per-YAML runs (safe resume).\")\n",
    "    yamls = list_yamls(input_dir)\n",
    "    for y in yamls:\n",
    "        if embeddings_exist_for_yaml(y, outdir):\n",
    "            print(f\"[SKIP-YAML] embeddings exist: {y.name}\")\n",
    "            continue\n",
    "\n",
    "        rc_y = run_cli(y, outdir)\n",
    "        if rc_y != 0:\n",
    "            print(f\"[FAIL-YAML] {y.name} (rc={rc_y}) — logged, continuing.\")\n",
    "            append_fail(outdir, y, rc_y)\n",
    "            continue\n",
    "\n",
    "        if not embeddings_exist_for_yaml(y, outdir):\n",
    "            print(f\"[WARN] {y.name} returned 0 but embeddings not found — logged.\")\n",
    "            append_fail(outdir, y, 999)\n",
    "\n",
    "    if all_embeddings_exist_for_dir(input_dir, outdir):\n",
    "        mark_done(outdir)\n",
    "    else:\n",
    "        print(f\"[INFO] {label} not fully complete; check {outdir}/{FAIL_LOG} and rerun later.\")\n",
    "\n",
    "\n",
    "def run_chunked_dataset(chunks_root: Path, out_root: Path, label: str):\n",
    "    for chunk_dir in list_chunk_dirs(chunks_root):\n",
    "        outdir = Path(out_root) / chunk_dir.name\n",
    "        run_dir_with_safe_resume(chunk_dir, outdir, f\"{label} {chunk_dir.name}\")\n",
    "\n",
    "\n",
    "def run_val_folder(val_yaml_dir: Path, out_root: Path):\n",
    "    outdir = Path(out_root) / \"val_full\"\n",
    "    run_dir_with_safe_resume(Path(val_yaml_dir), outdir, \"VAL val_full\")\n",
    "\n",
    "\n",
    "# ---- Execute ----\n",
    "run_chunked_dataset(TRAIN_CHUNKS_ROOT, BOLTZ_OUT_TRAIN, \"TRAIN\")\n",
    "run_val_folder(YAML_DIR_VAL, BOLTZ_OUT_VAL)\n",
    "run_chunked_dataset(TEST_CHUNKS_ROOT, BOLTZ_OUT_TEST, \"TEST\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tcr-multimodal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
