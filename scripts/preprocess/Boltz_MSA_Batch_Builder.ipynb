{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f4c8276a",
   "metadata": {},
   "source": [
    "# Boltz Batch Builder\n",
    "This notebook:\n",
    "1. Loads the full_positivies_hla_seq CSV (combined IEDB and VDJDB IMMREP positives with HLA sequences).\n",
    "2. Selects the first 100 usable pairs with peptide, TCRα, TCRβ, and HLA sequence.\n",
    "3. Writes **per-pair YAMLs** and runs jackhmmer to generate **A3M** files (TCRα, TCRβ, HLA).\n",
    "\n",
    "> Edit paths as needed to match repo. The generated YAML points to `data/raw/MSA/jackhmmer_msas/*.a3m` paths.\n",
    "> It also has a second section that does the same for negative pairs downloaded from IEDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9aaa0026",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # split the fasta file into alpha, beta, and mhc (only need to do this once)\n",
    "# from pathlib import Path\n",
    "\n",
    "# src = Path(\"/home/natasha/multimodal_model/data/raw/MSA/big_combo_subset_tcrs_50000_w_mhc_seqs.fasta\")\n",
    "# outdir = Path(\"/home/natasha/multimodal_model/data/raw/MSA/db_split\")\n",
    "# outdir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# fa_alpha = outdir / \"alpha.fasta\"\n",
    "# fa_beta  = outdir / \"beta.fasta\"\n",
    "# fa_mhc   = outdir / \"mhc.fasta\"\n",
    "\n",
    "# with src.open() as fin, \\\n",
    "#      fa_alpha.open(\"w\") as fa, \\\n",
    "#      fa_beta.open(\"w\") as fb, \\\n",
    "#      fa_mhc.open(\"w\") as fm:\n",
    "#     hdr, seq = None, []\n",
    "#     for ln in fin:\n",
    "#         if ln.startswith(\">\"):\n",
    "#             if hdr:\n",
    "#                 s = \"\".join(seq)\n",
    "#                 if hdr.endswith(\"_a\"):\n",
    "#                     fa.write(hdr + \"\\n\" + s + \"\\n\")\n",
    "#                 elif hdr.endswith(\"_b\"):\n",
    "#                     fb.write(hdr + \"\\n\" + s + \"\\n\")\n",
    "#                 elif \"mhc\" in hdr.lower():\n",
    "#                     fm.write(hdr + \"\\n\" + s + \"\\n\")\n",
    "#             hdr, seq = ln.strip(), []\n",
    "#         else:\n",
    "#             seq.append(ln.strip())\n",
    "#     # write last record\n",
    "#     if hdr:\n",
    "#         s = \"\".join(seq)\n",
    "#         if hdr.endswith(\"_a\"):\n",
    "#             fa.write(hdr + s + \"\\n\")\n",
    "#         elif hdr.endswith(\"_b\"):\n",
    "#             fb.write(hdr + s + \"\\n\")\n",
    "#         elif \"mhc\" in hdr.lower():\n",
    "#             fm.write(hdr + s + \"\\n\")\n",
    "\n",
    "# print(\"Split complete:\")\n",
    "# print(\"α:\", fa_alpha.stat().st_size, \"bytes\")\n",
    "# print(\"β:\", fa_beta.stat().st_size, \"bytes\")\n",
    "# print(\"MHC:\", fa_mhc.stat().st_size, \"bytes\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3531f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build MSA files using jackhmmer\n",
    "\n",
    "from pathlib import Path\n",
    "import subprocess, shutil, os\n",
    "import pandas as pd  # you use pd in cell 3\n",
    "import os, re, textwrap\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# -------- Paths --------\n",
    "BASE_DIR = Path(\"/home/natasha/multimodal_model\")\n",
    "DB_COMBINED = BASE_DIR / \"data\" / \"raw\" / \"MSA\" / \"big_combo_subset_tcrs_50000_w_mhc_seqs.fasta\"\n",
    "\n",
    "# use the split DBs created\n",
    "DBS = {\n",
    "    \"tcra\": BASE_DIR / \"data\" / \"raw\" / \"MSA\" / \"db_split\" / \"alpha.fasta\",\n",
    "    \"tcrb\": BASE_DIR / \"data\" / \"raw\" / \"MSA\" / \"db_split\" / \"beta.fasta\",\n",
    "    \"mhc\":  BASE_DIR / \"data\" / \"raw\" / \"MSA\" / \"db_split\" / \"mhc.fasta\",\n",
    "}\n",
    "def pick_db_for(stem: str) -> Path:\n",
    "    return DBS.get(stem, DB_COMBINED)\n",
    "\n",
    "OUT_ROOT = BASE_DIR / \"data\" / \"raw\" / \"MSA\" / \"jackhmmer_msas\"\n",
    "OUT_ROOT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# -------- Controls --------\n",
    "VERBOSE = False              # set False to silence prints\n",
    "KEEP_INTERMEDIATES = False   # set False to delete .sto/.tbl/.a3m after filtering\n",
    "\n",
    "# -------- jackhmmer / filtering parameters --------\n",
    "JACK_ITERS = 1\n",
    "EVALUE = 1e-10\n",
    "CPU_THREADS = 4\n",
    "CPU_THREADS = os.cpu_count() or 4\n",
    "\n",
    "MAX_SEQS = 64\n",
    "# keep identity de-dup very relaxed so hhfilter mostly just caps:\n",
    "ID_THR_DEFAULT = 100        # 100 = no ID-based collapse\n",
    "COV_THR_TCR     = 50\n",
    "COV_THR_MHC     = 30\n",
    "\n",
    "def have(cmd): return shutil.which(cmd) is not None\n",
    "if VERBOSE:\n",
    "    print(\"Deps:\",\n",
    "          \"jackhmmer\" if have(\"jackhmmer\") else \"MISSING\",\n",
    "          \"esl-reformat\" if have(\"esl-reformat\") else (\"reformat.pl\" if have(\"reformat.pl\") else \"MISSING\"),\n",
    "          \"hhfilter\" if have(\"hhfilter\") else \"MISSING\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "83d3cf0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Peptide</th>\n",
       "      <th>HLA</th>\n",
       "      <th>Va</th>\n",
       "      <th>Ja</th>\n",
       "      <th>CDR1a</th>\n",
       "      <th>CDR2a</th>\n",
       "      <th>CDR3a</th>\n",
       "      <th>CDR3a_extended</th>\n",
       "      <th>TCRa</th>\n",
       "      <th>Vb</th>\n",
       "      <th>...</th>\n",
       "      <th>CDR1b</th>\n",
       "      <th>CDR2b</th>\n",
       "      <th>CDR3b</th>\n",
       "      <th>CDR3b_extended</th>\n",
       "      <th>TCRb</th>\n",
       "      <th>references</th>\n",
       "      <th>receptor_id</th>\n",
       "      <th>just_10X</th>\n",
       "      <th>HLA_sequence</th>\n",
       "      <th>TCR_full</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TTDPSFLGRY</td>\n",
       "      <td>HLA-A*01:01</td>\n",
       "      <td>TRAV9-2*01</td>\n",
       "      <td>TRAJ6*01</td>\n",
       "      <td>ATGYPS</td>\n",
       "      <td>ATKADDK</td>\n",
       "      <td>AASGGSYIPT</td>\n",
       "      <td>CAASGGSYIPTF</td>\n",
       "      <td>GNSVTQMEGPVTLSEEAFLTINCTYTATGYPSLFWYVQYPGEGLQL...</td>\n",
       "      <td>TRBV9*01</td>\n",
       "      <td>...</td>\n",
       "      <td>SGDLS</td>\n",
       "      <td>YYNGEE</td>\n",
       "      <td>ASSVEETSAGGHEQF</td>\n",
       "      <td>CASSVEETSAGGHEQFF</td>\n",
       "      <td>DSGVTQTPKHLITATGQRVTLRCSPRSGDLSVYWYQQSLDQGLQFL...</td>\n",
       "      <td>http://www.iedb.org/reference/1039300</td>\n",
       "      <td>203509</td>\n",
       "      <td>True</td>\n",
       "      <td>MAVMAPRTLLLLLSGALALTQTWAGSHSMRYFFTSVSRPGRGEPRF...</td>\n",
       "      <td>GNSVTQMEGPVTLSEEAFLTINCTYTATGYPSLFWYVQYPGEGLQL...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>YLQPRTFLL</td>\n",
       "      <td>HLA-A*02:01</td>\n",
       "      <td>TRAV9-2*01</td>\n",
       "      <td>TRAJ45*01</td>\n",
       "      <td>ATGYPS</td>\n",
       "      <td>ATKADDK</td>\n",
       "      <td>AGGADGLT</td>\n",
       "      <td>CAGGADGLTF</td>\n",
       "      <td>GNSVTQMEGPVTLSEEAFLTINCTYTATGYPSLFWYVQYPGEGLQL...</td>\n",
       "      <td>TRBV2*01</td>\n",
       "      <td>...</td>\n",
       "      <td>SNHLY</td>\n",
       "      <td>FYNNEI</td>\n",
       "      <td>ASSEWQGEKLF</td>\n",
       "      <td>CASSEWQGEKLFF</td>\n",
       "      <td>EPEVTQTPSHQVTQMGQEVILRCVPISNHLYFYWYRQILGQKVEFL...</td>\n",
       "      <td>http://www.iedb.org/reference/1040829</td>\n",
       "      <td>208619</td>\n",
       "      <td>False</td>\n",
       "      <td>MAVMAPRTLVLLLSGALALTQTWAGSHSMRYFFTSVSRPGRGEPRF...</td>\n",
       "      <td>GNSVTQMEGPVTLSEEAFLTINCTYTATGYPSLFWYVQYPGEGLQL...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ILTGLNYEV</td>\n",
       "      <td>HLA-A*02:01</td>\n",
       "      <td>TRAV9-2*01</td>\n",
       "      <td>unknown</td>\n",
       "      <td>ATGYPS</td>\n",
       "      <td>ATKADDK</td>\n",
       "      <td>ALADMNRDDKII</td>\n",
       "      <td>CALADMNRDDKIIF</td>\n",
       "      <td>&lt;unk&gt;</td>\n",
       "      <td>TRBV9*01</td>\n",
       "      <td>...</td>\n",
       "      <td>SGDLS</td>\n",
       "      <td>YYNGEE</td>\n",
       "      <td>ASSVDPGQSYEQY</td>\n",
       "      <td>CASSVDPGQSYEQYF</td>\n",
       "      <td>&lt;unk&gt;</td>\n",
       "      <td>http://www.iedb.org/reference/1034376</td>\n",
       "      <td>29673</td>\n",
       "      <td>True</td>\n",
       "      <td>MAVMAPRTLVLLLSGALALTQTWAGSHSMRYFFTSVSRPGRGEPRF...</td>\n",
       "      <td>&lt;unk&gt;&lt;unk&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Peptide          HLA          Va         Ja   CDR1a    CDR2a  \\\n",
       "0  TTDPSFLGRY  HLA-A*01:01  TRAV9-2*01   TRAJ6*01  ATGYPS  ATKADDK   \n",
       "1   YLQPRTFLL  HLA-A*02:01  TRAV9-2*01  TRAJ45*01  ATGYPS  ATKADDK   \n",
       "2   ILTGLNYEV  HLA-A*02:01  TRAV9-2*01    unknown  ATGYPS  ATKADDK   \n",
       "\n",
       "          CDR3a  CDR3a_extended  \\\n",
       "0    AASGGSYIPT    CAASGGSYIPTF   \n",
       "1      AGGADGLT      CAGGADGLTF   \n",
       "2  ALADMNRDDKII  CALADMNRDDKIIF   \n",
       "\n",
       "                                                TCRa        Vb  ...  CDR1b  \\\n",
       "0  GNSVTQMEGPVTLSEEAFLTINCTYTATGYPSLFWYVQYPGEGLQL...  TRBV9*01  ...  SGDLS   \n",
       "1  GNSVTQMEGPVTLSEEAFLTINCTYTATGYPSLFWYVQYPGEGLQL...  TRBV2*01  ...  SNHLY   \n",
       "2                                              <unk>  TRBV9*01  ...  SGDLS   \n",
       "\n",
       "    CDR2b            CDR3b     CDR3b_extended  \\\n",
       "0  YYNGEE  ASSVEETSAGGHEQF  CASSVEETSAGGHEQFF   \n",
       "1  FYNNEI      ASSEWQGEKLF      CASSEWQGEKLFF   \n",
       "2  YYNGEE    ASSVDPGQSYEQY    CASSVDPGQSYEQYF   \n",
       "\n",
       "                                                TCRb  \\\n",
       "0  DSGVTQTPKHLITATGQRVTLRCSPRSGDLSVYWYQQSLDQGLQFL...   \n",
       "1  EPEVTQTPSHQVTQMGQEVILRCVPISNHLYFYWYRQILGQKVEFL...   \n",
       "2                                              <unk>   \n",
       "\n",
       "                              references receptor_id just_10X  \\\n",
       "0  http://www.iedb.org/reference/1039300      203509     True   \n",
       "1  http://www.iedb.org/reference/1040829      208619    False   \n",
       "2  http://www.iedb.org/reference/1034376       29673     True   \n",
       "\n",
       "                                        HLA_sequence  \\\n",
       "0  MAVMAPRTLLLLLSGALALTQTWAGSHSMRYFFTSVSRPGRGEPRF...   \n",
       "1  MAVMAPRTLVLLLSGALALTQTWAGSHSMRYFFTSVSRPGRGEPRF...   \n",
       "2  MAVMAPRTLVLLLSGALALTQTWAGSHSMRYFFTSVSRPGRGEPRF...   \n",
       "\n",
       "                                            TCR_full  \n",
       "0  GNSVTQMEGPVTLSEEAFLTINCTYTATGYPSLFWYVQYPGEGLQL...  \n",
       "1  GNSVTQMEGPVTLSEEAFLTINCTYTATGYPSLFWYVQYPGEGLQL...  \n",
       "2                                         <unk><unk>  \n",
       "\n",
       "[3 rows x 21 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# === Configure your paths ===\n",
    "#CSV_PATH = \"data/raw/HLA/full_positives_hla_seq.csv\"  # update if needed\n",
    "CSV_PATH = \"/home/natasha/multimodal_model/data/raw/HLA/full_positives_hla_seq.csv\"\n",
    "#BASE_DIR = Path(\".\")                      # point this to your repo root if running elsewhere\n",
    "BASE_DIR = Path(\"/home/natasha/multimodal_model\") #/ \"data\" / \"raw\"\n",
    "MSA_DIR  = BASE_DIR / \"data\" / \"raw\" / \"MSA\"\n",
    "PAIR_DIR = BASE_DIR / \"data\" / \"pairs\"\n",
    "MANI_DIR = BASE_DIR / \"data\" / \"manifests\"\n",
    "\n",
    "# create directories if they don't exist\n",
    "MSA_DIR.mkdir(parents=True, exist_ok=True)\n",
    "PAIR_DIR.mkdir(parents=True, exist_ok=True)\n",
    "MANI_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# === Load CSV and preview ===\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "df.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "776df4e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6000"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# === Filter usable rows ===\n",
    "required = [\"Peptide\",\"HLA_sequence\",\"TCRa\",\"TCRb\"]\n",
    "clean = df.dropna(subset=required).copy()\n",
    "\n",
    "def clean_seq(s: str) -> str:\n",
    "    import re\n",
    "    if not isinstance(s, str):\n",
    "        return \"\"\n",
    "    return re.sub(r\"[^A-Za-z]\", \"\", s).upper()\n",
    "\n",
    "for c in required:\n",
    "    clean[c] = clean[c].apply(clean_seq)\n",
    "\n",
    "# usable = clean[(clean[\"Peptide\"].str.len()>=8) & \n",
    "#                (clean[\"TCRa\"].str.len()>=50) & \n",
    "#                (clean[\"TCRb\"].str.len()>=50) & \n",
    "#                (clean[\"HLA_sequence\"].str.len()>=100)].head(100).copy()\n",
    "\n",
    "#usable = clean.head(100).copy()\n",
    "usable = clean[(clean[\"TCRa\"].str.len()>=50) | \n",
    "               (clean[\"TCRb\"].str.len()>=50)].head(1000).copy()\n",
    "# don't want to impose this restriction, as want to have missing data\n",
    "\n",
    "len(usable)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "985bd5e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50.0 5.0 0.0\n",
      "Number of 'UNK' in values_a: 50\n",
      "Number of 'UNK' in values_b: 5\n"
     ]
    }
   ],
   "source": [
    "#sum(usable['TCRa'] == '<unk>')\n",
    "for i, row in usable.iterrows():\n",
    "    usable.loc[i, 'missing_alpha'] = 1 if row['TCRa'] == 'UNK' else 0\n",
    "    usable.loc[i, 'missing_beta'] = 1 if row['TCRb'] == 'UNK' else 0\n",
    "    usable.loc[i, 'missing_mhc'] = 1 if row['HLA_sequence'] == 'UNK' else 0\n",
    "\n",
    "print(sum(usable['missing_alpha']),\n",
    "sum(usable['missing_beta']),\n",
    "sum(usable['missing_mhc']))\n",
    "\n",
    "values_a = [i for i in usable['TCRa']]\n",
    "values_b = [i for i in usable['TCRb']]\n",
    "\n",
    "\n",
    "num_unk_a = values_a.count('UNK')\n",
    "num_unk_b = values_b.count('UNK')\n",
    "print(f\"Number of 'UNK' in values_a: {num_unk_a}\")\n",
    "print(f\"Number of 'UNK' in values_b: {num_unk_b}\")\n",
    "\n",
    "# 152 missing alpha and 152 missing beta in the first 1000 runs - seems suspicious that it's the same?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cca3c2d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#usable.to_csv('/home/natasha/multimodal_model/data/raw/HLA/boltz_100_runs.csv', index=False)\n",
    "\n",
    "# save 1000 runs, with missing data \n",
    "usable.to_csv('/home/natasha/multimodal_model/data/raw/HLA/boltz_6000_runs.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "bfcdcdb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_yaml(pair_id: str, seqA: str, seqB: str, pep: str, mhc: str):\n",
    "\n",
    "    proteins = [\n",
    "        {\"protein\":{\"id\":\"A\",\"sequence\": seqA}}, #, \"msa\": yaml_msa_A}},\n",
    "        {\"protein\":{\"id\":\"B\",\"sequence\": seqB}}, #, \"msa\": yaml_msa_B}},\n",
    "        {\"protein\":{\"id\":\"C\",\"sequence\": pep}},  #,  \"msa\": \"empty\"}},\n",
    "        {\"protein\":{\"id\":\"D\",\"sequence\": mhc}},  #,  \"msa\": yaml_msa_D}},\n",
    "    ]\n",
    "    # if include_b2m:\n",
    "    #     proteins.append({\"protein\":{\"id\":\"E\",\"sequence\": B2M_SEQ, \"msa\": \"empty\"}})\n",
    "\n",
    "    yaml_text = \"version: 1\\nsequences:\\n\"\n",
    "    for p in proteins:\n",
    "        pid = p[\"protein\"][\"id\"]\n",
    "        seq = p[\"protein\"][\"sequence\"]\n",
    "        #msa = p[\"protein\"][\"msa\"]\n",
    "        # below removed \"msa: {msa}\"\n",
    "        yaml_text += textwrap.dedent(f\"\"\"          - protein:\n",
    "              id: {pid}\n",
    "              sequence: {seq}\n",
    "              msa: empty\n",
    "        \"\"\")\n",
    "    return yaml_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f1e9253f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/natasha/multimodal_model/data/pairs')"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PAIR_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "fc7072cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pair_id</th>\n",
       "      <th>yaml_path</th>\n",
       "      <th>pep_len</th>\n",
       "      <th>tcra_len</th>\n",
       "      <th>tcrb_len</th>\n",
       "      <th>hla_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pair_000</td>\n",
       "      <td>data/pairs/pair_000.yaml</td>\n",
       "      <td>10</td>\n",
       "      <td>112</td>\n",
       "      <td>117</td>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pair_001</td>\n",
       "      <td>data/pairs/pair_001.yaml</td>\n",
       "      <td>9</td>\n",
       "      <td>110</td>\n",
       "      <td>114</td>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pair_002</td>\n",
       "      <td>data/pairs/pair_002.yaml</td>\n",
       "      <td>10</td>\n",
       "      <td>112</td>\n",
       "      <td>114</td>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pair_003</td>\n",
       "      <td>data/pairs/pair_003.yaml</td>\n",
       "      <td>10</td>\n",
       "      <td>112</td>\n",
       "      <td>114</td>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pair_004</td>\n",
       "      <td>data/pairs/pair_004.yaml</td>\n",
       "      <td>9</td>\n",
       "      <td>114</td>\n",
       "      <td>115</td>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>pair_005</td>\n",
       "      <td>data/pairs/pair_005.yaml</td>\n",
       "      <td>10</td>\n",
       "      <td>113</td>\n",
       "      <td>115</td>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>pair_006</td>\n",
       "      <td>data/pairs/pair_006.yaml</td>\n",
       "      <td>10</td>\n",
       "      <td>113</td>\n",
       "      <td>115</td>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>pair_007</td>\n",
       "      <td>data/pairs/pair_007.yaml</td>\n",
       "      <td>10</td>\n",
       "      <td>113</td>\n",
       "      <td>115</td>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    pair_id                 yaml_path  pep_len  tcra_len  tcrb_len  hla_len\n",
       "0  pair_000  data/pairs/pair_000.yaml       10       112       117      365\n",
       "1  pair_001  data/pairs/pair_001.yaml        9       110       114      365\n",
       "2  pair_002  data/pairs/pair_002.yaml       10       112       114      365\n",
       "3  pair_003  data/pairs/pair_003.yaml       10       112       114      365\n",
       "4  pair_004  data/pairs/pair_004.yaml        9       114       115      365\n",
       "5  pair_005  data/pairs/pair_005.yaml       10       113       115      365\n",
       "6  pair_006  data/pairs/pair_006.yaml       10       113       115      365\n",
       "7  pair_007  data/pairs/pair_007.yaml       10       113       115      365"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# === Generate YAMLs + manifest ===\n",
    "rows = []\n",
    "for i, row in usable.reset_index(drop=True).iterrows():\n",
    "    pair_id = f\"pair_{i:03d}\"\n",
    "    yml = make_yaml(pair_id, row[\"TCRa\"], row[\"TCRb\"], row[\"Peptide\"], row[\"HLA_sequence\"])\n",
    "    yml_path = PAIR_DIR / f\"{pair_id}.yaml\"\n",
    "    yml_path.write_text(yml)\n",
    "\n",
    "    rows.append({\n",
    "        \"pair_id\": pair_id,\n",
    "        \"yaml_path\": f\"data/pairs/{pair_id}.yaml\",\n",
    "        #\"msa_A\": f\"data/raw/MSA/{pair_id}_A_tcra.a3m\",\n",
    "        #\"msa_B\": f\"data/raw/MSA/{pair_id}_B_tcrb.a3m\",\n",
    "        #\"msa_D\": f\"data/raw/MSA/{pair_id}_D_hla.a3m\",\n",
    "        \"pep_len\": len(row[\"Peptide\"]),\n",
    "        \"tcra_len\": len(row[\"TCRa\"]),\n",
    "        \"tcrb_len\": len(row[\"TCRb\"]),\n",
    "        \"hla_len\": len(row[\"HLA_sequence\"]),\n",
    "    })\n",
    "\n",
    "mani = pd.DataFrame(rows)\n",
    "mani_path = MANI_DIR / \"boltz_100_manifest.csv\"\n",
    "mani.to_csv(mani_path, index=False)\n",
    "mani.head(8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "aedc3d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# new functions\n",
    "def run(cmd):\n",
    "    p = subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)\n",
    "    out, err = p.communicate()\n",
    "    return p.returncode, out, err\n",
    "\n",
    "def sto_to_a3m(sto_path: Path, a3m_path: Path):\n",
    "    if have(\"esl-reformat\"):\n",
    "        code, out, err = run([\"esl-reformat\", \"a3m\", str(sto_path)])\n",
    "        if code == 0 and out:\n",
    "            a3m_path.write_text(out)\n",
    "            return True\n",
    "    if have(\"reformat.pl\"):\n",
    "        code, out, err = run([\"reformat.pl\", \"sto\", \"a3m\", str(sto_path), str(a3m_path)])\n",
    "        return code == 0 and a3m_path.exists()\n",
    "    return False\n",
    "\n",
    "# ---------- small helpers you call ----------\n",
    "def count_a3m(p: Path) -> int:\n",
    "    if not p.exists(): return -1\n",
    "    return sum(1 for ln in p.open() if ln.startswith('>'))\n",
    "\n",
    "def count_tbl_hits(tbl: Path) -> int:\n",
    "    if not tbl.exists(): return -1\n",
    "    return sum(1 for ln in tbl.read_text().splitlines() if ln and ln[0] != '#')\n",
    "\n",
    "def file_info(p: Path) -> str:\n",
    "    return f\"{p}  exists={p.exists()}  size={p.stat().st_size if p.exists() else 0}\"\n",
    "\n",
    "def assert_single_query(qfa: Path):\n",
    "    n = count_a3m(qfa)\n",
    "    if VERBOSE:\n",
    "        print(f\"[CHK] query FASTA {file_info(qfa)}  nseq={n}\")\n",
    "    if n != 1:\n",
    "        raise ValueError(f\"Query FASTA must contain exactly 1 sequence; got {n} in {qfa}\")\n",
    "\n",
    "# ---------- hhfilter wrapper (handles -maxseq vs -n) ----------\n",
    "def hhfilter_cap(in_a3m: Path, out_a3m: Path, max_seqs=MAX_SEQS, id_thr=ID_THR_DEFAULT, cov_thr=50):\n",
    "    if not have(\"hhfilter\"):\n",
    "        if VERBOSE: print(\"WARN: hhfilter not found on PATH; copying input → output\")\n",
    "        in_a3m.replace(out_a3m)\n",
    "        return True\n",
    "\n",
    "    code, out, err = run([\"hhfilter\", \"-h\"])\n",
    "    use_maxseq = (\"-maxseq\" in (out or \"\")) or (\"-maxseq\" in (err or \"\"))\n",
    "\n",
    "    cmd = [\"hhfilter\", \"-i\", str(in_a3m), \"-o\", str(out_a3m),\n",
    "           \"-id\", str(id_thr), \"-cov\", str(cov_thr)]\n",
    "    cmd += ([\"-maxseq\", str(max_seqs)] if use_maxseq else [\"-n\", str(max_seqs)])\n",
    "\n",
    "    if VERBOSE: print(\"[CMD]\", \" \".join(map(str, cmd)))\n",
    "    code, out, err = run(cmd)\n",
    "    if VERBOSE and err: print(\"[HHFILTER][stderr]\\n\", (err.strip()[:800]))\n",
    "    if VERBOSE: print(\"[HHFILTER] rc:\", code)\n",
    "    return code == 0 and out_a3m.exists()\n",
    "\n",
    "# ---------- main builder ----------\n",
    "def build_msa_for_chain(seq: str, out_dir: Path, stem: str) -> Path:\n",
    "    \"\"\"\n",
    "    seq: raw AA sequence (no gaps)\n",
    "    out_dir: where to write outputs\n",
    "    stem: base filename (e.g., 'tcra', 'tcrb', 'mhc')\n",
    "    returns: Path to final .a3m (filtered)\n",
    "    \"\"\"\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "    qfa = out_dir / f\"{stem}.fa\"\n",
    "    qfa.write_text(f\">{stem}\\n{seq}\\n\")\n",
    "\n",
    "    sto = out_dir / f\"{stem}.sto\"\n",
    "    raw_a3m = out_dir / f\"{stem}.a3m\"\n",
    "    filt_a3m = out_dir / f\"{stem}.filt.a3m\"\n",
    "    tbl = out_dir / f\"{stem}.tbl\"\n",
    "\n",
    "    db_fasta = pick_db_for(stem)\n",
    "\n",
    "    if VERBOSE:\n",
    "        print(f\"\\n=== {stem} ===\")\n",
    "        print(\"[PATHS]\", qfa.resolve())\n",
    "        print(\"[PATHS]\", sto.resolve())\n",
    "        print(\"[PATHS]\", raw_a3m.resolve())\n",
    "        print(\"[PATHS]\", filt_a3m.resolve())\n",
    "        print(\"[PATHS] DB_FASTA:\", db_fasta)\n",
    "\n",
    "    assert_single_query(qfa)\n",
    "\n",
    "    # jackhmmer (single pass, strict inclusion; split DB already speeds this up)\n",
    "    cmd = [\n",
    "        \"jackhmmer\",\n",
    "        \"-N\", str(JACK_ITERS),\n",
    "        \"-A\", str(sto),\n",
    "        \"--tblout\", str(tbl),\n",
    "        \"-E\", str(EVALUE),\n",
    "        \"--incE\", str(EVALUE),\n",
    "        \"--incdomE\", str(EVALUE),\n",
    "        \"--cpu\", str(CPU_THREADS),\n",
    "        str(qfa), str(db_fasta)\n",
    "    ]\n",
    "    if VERBOSE: print(\"[CMD]\", \" \".join(map(str, cmd)))\n",
    "    code, out, err = run(cmd)\n",
    "    if VERBOSE:\n",
    "        print(\"[JACK] rc:\", code)\n",
    "        if err: print(\"[JACK][stderr]\\n\", err.strip()[:800])\n",
    "        print(\"[CHK] STO:\", file_info(sto))\n",
    "        print(\"[CHK] TBL:\", file_info(tbl), \"hits=\", count_tbl_hits(tbl))\n",
    "\n",
    "    # Fallback if sto is bad\n",
    "    if code != 0 or (not sto.exists()) or sto.stat().st_size < 200:\n",
    "        if VERBOSE: print(\"WARN: bad/empty .sto → falling back to single-seq A3M\")\n",
    "        raw_a3m.write_text(f\">{stem}\\n{seq}\\n\")\n",
    "        raw = raw_a3m\n",
    "    else:\n",
    "        ok = sto_to_a3m(sto, raw_a3m)\n",
    "        if VERBOSE:\n",
    "            print(\"[CHK] A3M after sto->a3m:\", file_info(raw_a3m), \"nseq=\", count_a3m(raw_a3m))\n",
    "        raw = raw_a3m if ok else (out_dir / f\"{stem}.single.a3m\")\n",
    "        if not ok:\n",
    "            if VERBOSE: print(\"WARN: sto->a3m failed; using single-seq fallback\")\n",
    "            raw.write_text(f\">{stem}\\n{seq}\\n\")\n",
    "\n",
    "    # hhfilter (chain-specific coverage)\n",
    "    cov_thr = COV_THR_TCR if stem in (\"tcra\",\"tcrb\") else COV_THR_MHC\n",
    "    ok = hhfilter_cap(raw, filt_a3m, MAX_SEQS, ID_THR_DEFAULT, cov_thr)\n",
    "    if VERBOSE:\n",
    "        print(\"[CHK] filt A3M after hhfilter:\", file_info(filt_a3m), \"nseq=\", count_a3m(filt_a3m))\n",
    "\n",
    "    # Cleanup intermediates if requested\n",
    "    if not KEEP_INTERMEDIATES:\n",
    "        for p in (sto, tbl, raw_a3m):\n",
    "            try: p.unlink()\n",
    "            except Exception: pass\n",
    "\n",
    "    return filt_a3m\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "5f409e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_yaml_sequences(yaml_path):\n",
    "    \"\"\"Read sequences from YAML file and return dict with sequences by protein ID\"\"\"\n",
    "    with open(yaml_path, 'r') as f:\n",
    "        data = yaml.safe_load(f)\n",
    "    sequences = {}\n",
    "    for seq_data in data['sequences']:\n",
    "        protein = seq_data['protein']\n",
    "        sequences[protein['id']] = protein['sequence']\n",
    "    return sequences\n",
    "\n",
    "def update_yaml_with_msa(yaml_path, msa_paths):\n",
    "    \"\"\"Update YAML file with MSA paths for each protein\"\"\"\n",
    "    with open(yaml_path, 'r') as f:\n",
    "        data = yaml.safe_load(f)\n",
    "    for i, seq_data in enumerate(data['sequences']):\n",
    "        pid = seq_data['protein']['id']\n",
    "        if pid in msa_paths:\n",
    "            data['sequences'][i]['protein']['msa'] = msa_paths[pid]\n",
    "        elif pid == 'C':  # peptide\n",
    "            data['sequences'][i]['protein']['msa'] = 'empty'\n",
    "    with open(yaml_path, 'w') as f:\n",
    "        yaml.dump(data, f, default_flow_style=False, sort_keys=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "6c9209cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed pair_000\n",
      "Completed pair_001\n",
      "Completed pair_002\n",
      "Completed pair_003\n",
      "Completed pair_004\n",
      "Completed pair_005\n",
      "Completed pair_006\n",
      "Completed pair_007\n",
      "Completed pair_008\n",
      "Completed pair_009\n",
      "Completed pair_010\n",
      "Completed pair_011\n",
      "Completed pair_012\n",
      "Completed pair_013\n",
      "Completed pair_014\n",
      "Completed pair_015\n",
      "Completed pair_016\n",
      "Completed pair_017\n",
      "Completed pair_018\n",
      "Completed pair_019\n",
      "Completed pair_020\n",
      "Completed pair_021\n",
      "Completed pair_022\n",
      "Completed pair_023\n",
      "Completed pair_024\n",
      "Completed pair_025\n",
      "Completed pair_026\n",
      "Completed pair_027\n",
      "Completed pair_028\n",
      "Completed pair_029\n",
      "Completed pair_030\n",
      "Completed pair_031\n",
      "Completed pair_032\n",
      "Completed pair_033\n",
      "Completed pair_034\n",
      "Completed pair_035\n",
      "Completed pair_036\n",
      "Completed pair_037\n",
      "Completed pair_038\n",
      "Completed pair_039\n",
      "Completed pair_040\n",
      "Completed pair_041\n",
      "Completed pair_042\n",
      "Completed pair_043\n",
      "Completed pair_044\n",
      "Completed pair_045\n",
      "Completed pair_046\n",
      "Completed pair_047\n",
      "Completed pair_048\n",
      "Completed pair_049\n",
      "Completed pair_050\n",
      "Completed pair_051\n",
      "Completed pair_052\n",
      "Completed pair_053\n",
      "Completed pair_054\n",
      "Completed pair_055\n",
      "Completed pair_056\n",
      "Completed pair_057\n",
      "Completed pair_058\n",
      "Completed pair_059\n",
      "Completed pair_060\n",
      "Completed pair_061\n",
      "Completed pair_062\n",
      "Completed pair_063\n",
      "Completed pair_064\n",
      "Completed pair_065\n",
      "Completed pair_066\n",
      "Completed pair_067\n",
      "Completed pair_068\n",
      "Completed pair_069\n",
      "Completed pair_070\n",
      "Completed pair_071\n",
      "Completed pair_072\n",
      "Completed pair_073\n",
      "Completed pair_074\n",
      "Completed pair_075\n",
      "Completed pair_076\n",
      "Completed pair_077\n",
      "Completed pair_078\n",
      "Completed pair_079\n",
      "Completed pair_080\n",
      "Completed pair_081\n",
      "Completed pair_082\n",
      "Completed pair_083\n",
      "Completed pair_084\n",
      "Completed pair_085\n",
      "Completed pair_086\n",
      "Completed pair_087\n",
      "Completed pair_088\n",
      "Completed pair_089\n",
      "Completed pair_090\n",
      "Completed pair_091\n",
      "Completed pair_092\n",
      "Completed pair_093\n",
      "Completed pair_094\n",
      "Completed pair_095\n",
      "Completed pair_096\n",
      "Completed pair_097\n",
      "Completed pair_098\n",
      "Completed pair_099\n",
      "\n",
      "Completed MSA building for 100 pairs\n"
     ]
    }
   ],
   "source": [
    "# new MSA building\n",
    "\n",
    "import yaml\n",
    "\n",
    "manifest = pd.read_csv(mani_path)   # mani_path must be defined earlier\n",
    "if VERBOSE:\n",
    "    display(manifest.head(3))\n",
    "\n",
    "# def read_yaml_sequences(yaml_path):\n",
    "#     \"\"\"Read sequences from YAML file and return dict with sequences by protein ID\"\"\"\n",
    "#     with open(yaml_path, 'r') as f:\n",
    "#         data = yaml.safe_load(f)\n",
    "#     sequences = {}\n",
    "#     for seq_data in data['sequences']:\n",
    "#         protein = seq_data['protein']\n",
    "#         sequences[protein['id']] = protein['sequence']\n",
    "#     return sequences\n",
    "\n",
    "# def update_yaml_with_msa(yaml_path, msa_paths):\n",
    "#     \"\"\"Update YAML file with MSA paths for each protein\"\"\"\n",
    "#     with open(yaml_path, 'r') as f:\n",
    "#         data = yaml.safe_load(f)\n",
    "#     for i, seq_data in enumerate(data['sequences']):\n",
    "#         pid = seq_data['protein']['id']\n",
    "#         if pid in msa_paths:\n",
    "#             data['sequences'][i]['protein']['msa'] = msa_paths[pid]\n",
    "#         elif pid == 'C':  # peptide\n",
    "#             data['sequences'][i]['protein']['msa'] = 'empty'\n",
    "#     with open(yaml_path, 'w') as f:\n",
    "#         yaml.dump(data, f, default_flow_style=False, sort_keys=False)\n",
    "\n",
    "results = []\n",
    "for _, row in manifest.iterrows():\n",
    "    pair_id = row[\"pair_id\"]\n",
    "    yaml_path = BASE_DIR / row[\"yaml_path\"]\n",
    "\n",
    "    sequences = read_yaml_sequences(yaml_path)\n",
    "\n",
    "    pair_out = OUT_ROOT / pair_id\n",
    "    pair_out.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    msa_paths = {}\n",
    "\n",
    "    if 'A' in sequences:\n",
    "        msa_tcra = build_msa_for_chain(sequences['A'], pair_out, \"tcra\")\n",
    "        msa_paths['A'] = f\"/home/natasha/multimodal_model/data/raw/MSA/jackhmmer_msas/{pair_id}/tcra.filt.a3m\"\n",
    "\n",
    "    if 'B' in sequences:\n",
    "        msa_tcrb = build_msa_for_chain(sequences['B'], pair_out, \"tcrb\")\n",
    "        msa_paths['B'] = f\"/home/natasha/multimodal_model/data/raw/MSA/jackhmmer_msas/{pair_id}/tcrb.filt.a3m\"\n",
    "\n",
    "    if 'D' in sequences:\n",
    "        msa_mhc = build_msa_for_chain(sequences['D'], pair_out, \"mhc\")\n",
    "        msa_paths['D'] = f\"/home/natasha/multimodal_model/data/raw/MSA/jackhmmer_msas/{pair_id}/mhc.filt.a3m\"\n",
    "\n",
    "    update_yaml_with_msa(yaml_path, msa_paths)\n",
    "\n",
    "    results.append((pair_id, msa_paths))\n",
    "    if VERBOSE:\n",
    "        print(f\"Completed {pair_id}: {list(msa_paths.keys())}\")\n",
    "    print(f\"Completed {pair_id}\")\n",
    "\n",
    "print(f\"\\nCompleted MSA building for {len(results)} pairs\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3bb33f3",
   "metadata": {},
   "source": [
    "##### Negative Dataset Create MSAs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "397cedf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Negative pairs\n",
    "\n",
    "# === Load CSV and preview ===\n",
    "CSV_PATH = \"/home/natasha/multimodal_model/data/raw/HLA/IEDB_Negatives_HLA_class_I_with_HLA_seq.csv\"\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "df.head(3)\n",
    "\n",
    "# === Filter usable rows ===\n",
    "required = [\"Peptide\",\"HLA_sequence\",\"TCR_alpha\",\"TCR_beta\"]\n",
    "clean = df.dropna(subset=required).copy()\n",
    "\n",
    "def clean_seq(s: str) -> str:\n",
    "    import re\n",
    "    if not isinstance(s, str):\n",
    "        return \"\"\n",
    "    return re.sub(r\"[^A-Za-z]\", \"\", s).upper()\n",
    "\n",
    "for c in required:\n",
    "    clean[c] = clean[c].apply(clean_seq)\n",
    "\n",
    "usable = clean[(clean[\"Peptide\"].str.len()>=8) & \n",
    "               (clean[\"TCR_alpha\"].str.len()>=50) & \n",
    "               (clean[\"TCR_beta\"].str.len()>=50) & \n",
    "               (clean[\"HLA_sequence\"].str.len()>=100)].head(100).copy()\n",
    "\n",
    "len(usable)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "dd4d56bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "NEG_PAIR_DIR = Path(\"/home/natasha/multimodal_model/data/negative_pairs\")\n",
    "NEG_PAIR_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "NEG_MANI_DIR = Path(\"/home/natasha/multimodal_model/data/negative_manifests\")\n",
    "NEG_MANI_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "54e065cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pair_id</th>\n",
       "      <th>yaml_path</th>\n",
       "      <th>pep_len</th>\n",
       "      <th>tcra_len</th>\n",
       "      <th>tcrb_len</th>\n",
       "      <th>hla_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pair_000</td>\n",
       "      <td>data/negative_pairs/pair_000.yaml</td>\n",
       "      <td>9</td>\n",
       "      <td>203</td>\n",
       "      <td>241</td>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pair_001</td>\n",
       "      <td>data/negative_pairs/pair_001.yaml</td>\n",
       "      <td>9</td>\n",
       "      <td>194</td>\n",
       "      <td>243</td>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pair_002</td>\n",
       "      <td>data/negative_pairs/pair_002.yaml</td>\n",
       "      <td>10</td>\n",
       "      <td>194</td>\n",
       "      <td>243</td>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pair_003</td>\n",
       "      <td>data/negative_pairs/pair_003.yaml</td>\n",
       "      <td>9</td>\n",
       "      <td>194</td>\n",
       "      <td>243</td>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pair_004</td>\n",
       "      <td>data/negative_pairs/pair_004.yaml</td>\n",
       "      <td>9</td>\n",
       "      <td>201</td>\n",
       "      <td>244</td>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>pair_005</td>\n",
       "      <td>data/negative_pairs/pair_005.yaml</td>\n",
       "      <td>9</td>\n",
       "      <td>205</td>\n",
       "      <td>241</td>\n",
       "      <td>362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>pair_006</td>\n",
       "      <td>data/negative_pairs/pair_006.yaml</td>\n",
       "      <td>9</td>\n",
       "      <td>206</td>\n",
       "      <td>242</td>\n",
       "      <td>362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>pair_007</td>\n",
       "      <td>data/negative_pairs/pair_007.yaml</td>\n",
       "      <td>9</td>\n",
       "      <td>206</td>\n",
       "      <td>242</td>\n",
       "      <td>362</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    pair_id                          yaml_path  pep_len  tcra_len  tcrb_len  \\\n",
       "0  pair_000  data/negative_pairs/pair_000.yaml        9       203       241   \n",
       "1  pair_001  data/negative_pairs/pair_001.yaml        9       194       243   \n",
       "2  pair_002  data/negative_pairs/pair_002.yaml       10       194       243   \n",
       "3  pair_003  data/negative_pairs/pair_003.yaml        9       194       243   \n",
       "4  pair_004  data/negative_pairs/pair_004.yaml        9       201       244   \n",
       "5  pair_005  data/negative_pairs/pair_005.yaml        9       205       241   \n",
       "6  pair_006  data/negative_pairs/pair_006.yaml        9       206       242   \n",
       "7  pair_007  data/negative_pairs/pair_007.yaml        9       206       242   \n",
       "\n",
       "   hla_len  \n",
       "0      365  \n",
       "1      365  \n",
       "2      365  \n",
       "3      365  \n",
       "4      365  \n",
       "5      362  \n",
       "6      362  \n",
       "7      362  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# do it for negative pairs\n",
    "\n",
    "# === Generate YAMLs + A3Ms + manifest ===\n",
    "rows = []\n",
    "for i, row in usable.reset_index(drop=True).iterrows():\n",
    "    pair_id = f\"pair_{i:03d}\"\n",
    "    yml = make_yaml(pair_id, row[\"TCR_alpha\"], row[\"TCR_beta\"], row[\"Peptide\"], row[\"HLA_sequence\"])\n",
    "    yml_path = NEG_PAIR_DIR / f\"{pair_id}.yaml\"\n",
    "    yml_path.write_text(yml)\n",
    "\n",
    "    rows.append({\n",
    "        \"pair_id\": pair_id,\n",
    "        \"yaml_path\": f\"data/negative_pairs/{pair_id}.yaml\",\n",
    "        \"pep_len\": len(row[\"Peptide\"]),\n",
    "        \"tcra_len\": len(row[\"TCR_alpha\"]),\n",
    "        \"tcrb_len\": len(row[\"TCR_beta\"]),\n",
    "        \"hla_len\": len(row[\"HLA_sequence\"]),\n",
    "    })\n",
    "\n",
    "mani = pd.DataFrame(rows)\n",
    "mani_path = NEG_MANI_DIR / \"boltz_100_manifest.csv\"\n",
    "mani.to_csv(mani_path, index=False)\n",
    "mani.head(8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "9c0ec1e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUT_ROOT = Path(\"/home/natasha/multimodal_model/data/raw/MSA/jackhmmer_msas_negative\")\n",
    "OUT_ROOT.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "4aabbea8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed pair_000\n",
      "Completed pair_001\n",
      "Completed pair_002\n",
      "Completed pair_003\n",
      "Completed pair_004\n",
      "Completed pair_005\n",
      "Completed pair_006\n",
      "Completed pair_007\n",
      "Completed pair_008\n",
      "Completed pair_009\n",
      "Completed pair_010\n",
      "Completed pair_011\n",
      "Completed pair_012\n",
      "Completed pair_013\n",
      "Completed pair_014\n",
      "Completed pair_015\n",
      "Completed pair_016\n",
      "Completed pair_017\n",
      "Completed pair_018\n",
      "Completed pair_019\n",
      "Completed pair_020\n",
      "Completed pair_021\n",
      "Completed pair_022\n",
      "Completed pair_023\n",
      "Completed pair_024\n",
      "Completed pair_025\n",
      "Completed pair_026\n",
      "Completed pair_027\n",
      "Completed pair_028\n",
      "Completed pair_029\n",
      "Completed pair_030\n",
      "Completed pair_031\n",
      "Completed pair_032\n",
      "Completed pair_033\n",
      "Completed pair_034\n",
      "Completed pair_035\n",
      "Completed pair_036\n",
      "Completed pair_037\n",
      "Completed pair_038\n",
      "Completed pair_039\n",
      "Completed pair_040\n",
      "Completed pair_041\n",
      "Completed pair_042\n",
      "Completed pair_043\n",
      "Completed pair_044\n",
      "Completed pair_045\n",
      "Completed pair_046\n",
      "Completed pair_047\n",
      "Completed pair_048\n",
      "Completed pair_049\n",
      "Completed pair_050\n",
      "Completed pair_051\n",
      "Completed pair_052\n",
      "Completed pair_053\n",
      "Completed pair_054\n",
      "Completed pair_055\n",
      "Completed pair_056\n",
      "Completed pair_057\n",
      "Completed pair_058\n",
      "Completed pair_059\n",
      "Completed pair_060\n",
      "Completed pair_061\n",
      "Completed pair_062\n",
      "Completed pair_063\n",
      "Completed pair_064\n",
      "Completed pair_065\n",
      "Completed pair_066\n",
      "Completed pair_067\n",
      "Completed pair_068\n",
      "Completed pair_069\n",
      "Completed pair_070\n",
      "Completed pair_071\n",
      "Completed pair_072\n",
      "Completed pair_073\n",
      "Completed pair_074\n",
      "Completed pair_075\n",
      "Completed pair_076\n",
      "Completed pair_077\n",
      "Completed pair_078\n",
      "Completed pair_079\n",
      "Completed pair_080\n",
      "Completed pair_081\n",
      "Completed pair_082\n",
      "Completed pair_083\n",
      "Completed pair_084\n",
      "Completed pair_085\n",
      "Completed pair_086\n",
      "Completed pair_087\n",
      "Completed pair_088\n",
      "Completed pair_089\n",
      "Completed pair_090\n",
      "Completed pair_091\n",
      "Completed pair_092\n",
      "Completed pair_093\n",
      "Completed pair_094\n",
      "Completed pair_095\n",
      "Completed pair_096\n",
      "Completed pair_097\n",
      "Completed pair_098\n",
      "Completed pair_099\n",
      "\n",
      "Completed MSA building for 100 pairs\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "\n",
    "manifest = pd.read_csv(mani_path)   # mani_path must be defined earlier\n",
    "if VERBOSE:\n",
    "    display(manifest.head(3))\n",
    "\n",
    "results = []\n",
    "for _, row in manifest.iterrows():\n",
    "    pair_id = row[\"pair_id\"]\n",
    "    yaml_path = BASE_DIR / row[\"yaml_path\"]\n",
    "\n",
    "    sequences = read_yaml_sequences(yaml_path)\n",
    "\n",
    "    pair_out = OUT_ROOT / pair_id\n",
    "    pair_out.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    msa_paths = {}\n",
    "\n",
    "    if 'A' in sequences:\n",
    "        msa_tcra = build_msa_for_chain(sequences['A'], pair_out, \"tcra\")\n",
    "        msa_paths['A'] = f\"/home/natasha/multimodal_model/data/raw/MSA/jackhmmer_msas_negative/{pair_id}/tcra.filt.a3m\"\n",
    "\n",
    "    if 'B' in sequences:\n",
    "        msa_tcrb = build_msa_for_chain(sequences['B'], pair_out, \"tcrb\")\n",
    "        msa_paths['B'] = f\"/home/natasha/multimodal_model/data/raw/MSA/jackhmmer_msas_negative/{pair_id}/tcrb.filt.a3m\"\n",
    "\n",
    "    if 'D' in sequences:\n",
    "        msa_mhc = build_msa_for_chain(sequences['D'], pair_out, \"mhc\")\n",
    "        msa_paths['D'] = f\"/home/natasha/multimodal_model/data/raw/MSA/jackhmmer_msas_negative/{pair_id}/mhc.filt.a3m\"\n",
    "\n",
    "    update_yaml_with_msa(yaml_path, msa_paths)\n",
    "\n",
    "    results.append((pair_id, msa_paths))\n",
    "    if VERBOSE:\n",
    "        print(f\"Completed {pair_id}: {list(msa_paths.keys())}\")\n",
    "    print(f\"Completed {pair_id}\")\n",
    "\n",
    "print(f\"\\nCompleted MSA building for {len(results)} pairs\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77db8d4e",
   "metadata": {},
   "source": [
    "##### Split Data in Train, Validate and Test and Create Pairs to Run in Boltz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a95cae4",
   "metadata": {},
   "source": [
    "Step 1: Split the data into the categories as outlined in IMMREP2025\n",
    "- keep the most promiscuous peptides and TCRs in the training set to ensure training set is big enough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "2c828ef9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Peptide</th>\n",
       "      <th>HLA</th>\n",
       "      <th>Va</th>\n",
       "      <th>Ja</th>\n",
       "      <th>CDR1a</th>\n",
       "      <th>CDR2a</th>\n",
       "      <th>CDR3a</th>\n",
       "      <th>CDR3a_extended</th>\n",
       "      <th>TCRa</th>\n",
       "      <th>Vb</th>\n",
       "      <th>...</th>\n",
       "      <th>CDR1b</th>\n",
       "      <th>CDR2b</th>\n",
       "      <th>CDR3b</th>\n",
       "      <th>CDR3b_extended</th>\n",
       "      <th>TCRb</th>\n",
       "      <th>references</th>\n",
       "      <th>receptor_id</th>\n",
       "      <th>just_10X</th>\n",
       "      <th>HLA_sequence</th>\n",
       "      <th>TCR_full</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TTDPSFLGRY</td>\n",
       "      <td>HLA-A*01:01</td>\n",
       "      <td>TRAV9-2*01</td>\n",
       "      <td>TRAJ6*01</td>\n",
       "      <td>ATGYPS</td>\n",
       "      <td>ATKADDK</td>\n",
       "      <td>AASGGSYIPT</td>\n",
       "      <td>CAASGGSYIPTF</td>\n",
       "      <td>GNSVTQMEGPVTLSEEAFLTINCTYTATGYPSLFWYVQYPGEGLQL...</td>\n",
       "      <td>TRBV9*01</td>\n",
       "      <td>...</td>\n",
       "      <td>SGDLS</td>\n",
       "      <td>YYNGEE</td>\n",
       "      <td>ASSVEETSAGGHEQF</td>\n",
       "      <td>CASSVEETSAGGHEQFF</td>\n",
       "      <td>DSGVTQTPKHLITATGQRVTLRCSPRSGDLSVYWYQQSLDQGLQFL...</td>\n",
       "      <td>http://www.iedb.org/reference/1039300</td>\n",
       "      <td>203509</td>\n",
       "      <td>True</td>\n",
       "      <td>MAVMAPRTLLLLLSGALALTQTWAGSHSMRYFFTSVSRPGRGEPRF...</td>\n",
       "      <td>GNSVTQMEGPVTLSEEAFLTINCTYTATGYPSLFWYVQYPGEGLQL...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>YLQPRTFLL</td>\n",
       "      <td>HLA-A*02:01</td>\n",
       "      <td>TRAV9-2*01</td>\n",
       "      <td>TRAJ45*01</td>\n",
       "      <td>ATGYPS</td>\n",
       "      <td>ATKADDK</td>\n",
       "      <td>AGGADGLT</td>\n",
       "      <td>CAGGADGLTF</td>\n",
       "      <td>GNSVTQMEGPVTLSEEAFLTINCTYTATGYPSLFWYVQYPGEGLQL...</td>\n",
       "      <td>TRBV2*01</td>\n",
       "      <td>...</td>\n",
       "      <td>SNHLY</td>\n",
       "      <td>FYNNEI</td>\n",
       "      <td>ASSEWQGEKLF</td>\n",
       "      <td>CASSEWQGEKLFF</td>\n",
       "      <td>EPEVTQTPSHQVTQMGQEVILRCVPISNHLYFYWYRQILGQKVEFL...</td>\n",
       "      <td>http://www.iedb.org/reference/1040829</td>\n",
       "      <td>208619</td>\n",
       "      <td>False</td>\n",
       "      <td>MAVMAPRTLVLLLSGALALTQTWAGSHSMRYFFTSVSRPGRGEPRF...</td>\n",
       "      <td>GNSVTQMEGPVTLSEEAFLTINCTYTATGYPSLFWYVQYPGEGLQL...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ILTGLNYEV</td>\n",
       "      <td>HLA-A*02:01</td>\n",
       "      <td>TRAV9-2*01</td>\n",
       "      <td>unknown</td>\n",
       "      <td>ATGYPS</td>\n",
       "      <td>ATKADDK</td>\n",
       "      <td>ALADMNRDDKII</td>\n",
       "      <td>CALADMNRDDKIIF</td>\n",
       "      <td>&lt;unk&gt;</td>\n",
       "      <td>TRBV9*01</td>\n",
       "      <td>...</td>\n",
       "      <td>SGDLS</td>\n",
       "      <td>YYNGEE</td>\n",
       "      <td>ASSVDPGQSYEQY</td>\n",
       "      <td>CASSVDPGQSYEQYF</td>\n",
       "      <td>&lt;unk&gt;</td>\n",
       "      <td>http://www.iedb.org/reference/1034376</td>\n",
       "      <td>29673</td>\n",
       "      <td>True</td>\n",
       "      <td>MAVMAPRTLVLLLSGALALTQTWAGSHSMRYFFTSVSRPGRGEPRF...</td>\n",
       "      <td>&lt;unk&gt;&lt;unk&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Peptide          HLA          Va         Ja   CDR1a    CDR2a  \\\n",
       "0  TTDPSFLGRY  HLA-A*01:01  TRAV9-2*01   TRAJ6*01  ATGYPS  ATKADDK   \n",
       "1   YLQPRTFLL  HLA-A*02:01  TRAV9-2*01  TRAJ45*01  ATGYPS  ATKADDK   \n",
       "2   ILTGLNYEV  HLA-A*02:01  TRAV9-2*01    unknown  ATGYPS  ATKADDK   \n",
       "\n",
       "          CDR3a  CDR3a_extended  \\\n",
       "0    AASGGSYIPT    CAASGGSYIPTF   \n",
       "1      AGGADGLT      CAGGADGLTF   \n",
       "2  ALADMNRDDKII  CALADMNRDDKIIF   \n",
       "\n",
       "                                                TCRa        Vb  ...  CDR1b  \\\n",
       "0  GNSVTQMEGPVTLSEEAFLTINCTYTATGYPSLFWYVQYPGEGLQL...  TRBV9*01  ...  SGDLS   \n",
       "1  GNSVTQMEGPVTLSEEAFLTINCTYTATGYPSLFWYVQYPGEGLQL...  TRBV2*01  ...  SNHLY   \n",
       "2                                              <unk>  TRBV9*01  ...  SGDLS   \n",
       "\n",
       "    CDR2b            CDR3b     CDR3b_extended  \\\n",
       "0  YYNGEE  ASSVEETSAGGHEQF  CASSVEETSAGGHEQFF   \n",
       "1  FYNNEI      ASSEWQGEKLF      CASSEWQGEKLFF   \n",
       "2  YYNGEE    ASSVDPGQSYEQY    CASSVDPGQSYEQYF   \n",
       "\n",
       "                                                TCRb  \\\n",
       "0  DSGVTQTPKHLITATGQRVTLRCSPRSGDLSVYWYQQSLDQGLQFL...   \n",
       "1  EPEVTQTPSHQVTQMGQEVILRCVPISNHLYFYWYRQILGQKVEFL...   \n",
       "2                                              <unk>   \n",
       "\n",
       "                              references receptor_id just_10X  \\\n",
       "0  http://www.iedb.org/reference/1039300      203509     True   \n",
       "1  http://www.iedb.org/reference/1040829      208619    False   \n",
       "2  http://www.iedb.org/reference/1034376       29673     True   \n",
       "\n",
       "                                        HLA_sequence  \\\n",
       "0  MAVMAPRTLLLLLSGALALTQTWAGSHSMRYFFTSVSRPGRGEPRF...   \n",
       "1  MAVMAPRTLVLLLSGALALTQTWAGSHSMRYFFTSVSRPGRGEPRF...   \n",
       "2  MAVMAPRTLVLLLSGALALTQTWAGSHSMRYFFTSVSRPGRGEPRF...   \n",
       "\n",
       "                                            TCR_full  \n",
       "0  GNSVTQMEGPVTLSEEAFLTINCTYTATGYPSLFWYVQYPGEGLQL...  \n",
       "1  GNSVTQMEGPVTLSEEAFLTINCTYTATGYPSLFWYVQYPGEGLQL...  \n",
       "2                                         <unk><unk>  \n",
       "\n",
       "[3 rows x 21 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# === Configure your paths ===\n",
    "#CSV_PATH = \"data/raw/HLA/full_positives_hla_seq.csv\"  # update if needed\n",
    "CSV_PATH = \"/home/natasha/multimodal_model/data/raw/HLA/full_positives_hla_seq.csv\"\n",
    "#BASE_DIR = Path(\".\")                      # point this to your repo root if running elsewhere\n",
    "BASE_DIR  = Path(\"/home/natasha/multimodal_model\") #/ \"data\" / \"raw\"\n",
    "MSA_DIR   = BASE_DIR / \"data\" / \"raw\" / \"MSA\"\n",
    "TRAIN_DIR = BASE_DIR / \"data\" / \"train\"\n",
    "VAL_DIR   = BASE_DIR / \"data\" / \"val\"\n",
    "TEST_DIR  = BASE_DIR / \"data\" / \"test\"\n",
    "#PAIR_DIR  = BASE_DIR / \"data\" / \"pairs\"\n",
    "MANI_DIR  = BASE_DIR / \"data\" / \"manifests\"\n",
    "\n",
    "# create directories if they don't exist\n",
    "MSA_DIR.mkdir(parents=True, exist_ok=True)\n",
    "#PAIR_DIR.mkdir(parents=True, exist_ok=True)\n",
    "MANI_DIR.mkdir(parents=True, exist_ok=True)\n",
    "TRAIN_DIR.mkdir(parents=True, exist_ok=True)\n",
    "VAL_DIR.mkdir(parents=True, exist_ok=True)\n",
    "TEST_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# === Load CSV and preview ===\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "df.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8fe46a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# ============================================================\n",
    "# 0. Hyperparams & constants\n",
    "# ============================================================\n",
    "\n",
    "RNG_SEED = 42\n",
    "rng = np.random.default_rng(RNG_SEED)\n",
    "\n",
    "# Peptides you *never* want to end up in unseen categories\n",
    "PEPTIDES_TO_KEEP = [\n",
    "    \"KLGGALQAK\", \"GILGFVFTL\", \"AVFDRKSDAK\", \"RAKFKQLL\", \"SPRWYFYYL\",\n",
    "    \"YLQPRTFLL\", \"TTDPSFLGRY\", \"GLCTLVAML\", \"RVRAYTYSK\", \"IVTDFSVIK\",\n",
    "    \"LLWNGPMAV\", \"LLLDRLNQL\", \"NLVPMVATV\", \"LLAGIGTVPI\", \"RLRAEAQVK\",\n",
    "    \"ELAGIGILTV\", \"YVLDHLIVV\", \"LTDEMIAQY\", \"CINGVCWTV\", \"TPRVTGGGAM\",\n",
    "    \"VMATRRNVL\", \"KTFPPTEPK\", \"QYIKWPWYI\", \"DATYQRTRALVR\", \"NQKLIANQF\",\n",
    "    \"FLRGRAYGL\", \"CTELKLSDY\", \"ATDALMTGF\", \"RPPIFIRRL\", \"NYNYLYRLF\",\n",
    "    \"FLYALALLL\", \"VMTTVLATL\", \"CLGGLLTMV\", \"KSKRTPMGF\", \"RPHERNGFTVL\",\n",
    "    \"MEVTPSGTWL\", \"FTSDYYQLY\", \"RPIIRPATL\", \"ALAGIGILTV\", \"LLYDANYFL\",\n",
    "    \"HPVTKYIM\", \"RLPGVLPRA\", \"RFPLTFGWCF\", \"VYFLQSINF\", \"PTDNYITTY\",\n",
    "    \"ALWEIQQVV\", \"QAKWRLQTL\", \"RTATKQYNV\", \"LLFGYPVYV\"\n",
    "]\n",
    "\n",
    "# Backbone HLAs that should always stay in train (can also appear in val/test,\n",
    "# but not as \"unseen_HLA\" regimes)\n",
    "BACKBONE_HLAS = {\n",
    "    'HLA-A*02:01',\n",
    "    'HLA-A*01:01',\n",
    "    'HLA-A*24:02',\n",
    "    'HLA-B*07:02',\n",
    "    'HLA-B*08:01',\n",
    "    'HLA-A*03:01',\n",
    "    'HLA-A*11:01',\n",
    "}\n",
    "\n",
    "# How many HLAs to use as explicit unseen-HLA regimes\n",
    "N_TEST_UNSEEN_HLA = 2\n",
    "N_VAL_UNSEEN_HLA  = 2\n",
    "\n",
    "# Minimum peptides for an HLA to be eligible as an \"unseen HLA\" regime\n",
    "MIN_PEPTIDES_UNSEEN_HLA_TEST = 10\n",
    "MIN_PEPTIDES_UNSEEN_HLA_VAL  = 10  # you can lower this if needed\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 1. Pre-processing\n",
    "# ============================================================\n",
    "\n",
    "def preprocess_df(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Clean up TCR chains, build TCR_full and masks.\"\"\"\n",
    "    df = df.copy()\n",
    "\n",
    "    # 1. Fill empty/nan values with 'X' token\n",
    "    df['TCRa'] = df['TCRa'].fillna('X')\n",
    "    df['TCRb'] = df['TCRb'].fillna('X')\n",
    "\n",
    "    # Replace empty strings with 'X'\n",
    "    df.loc[df['TCRa'] == '', 'TCRa'] = 'X'\n",
    "    df.loc[df['TCRb'] == '', 'TCRb'] = 'X'\n",
    "\n",
    "    # Build TCR_full and alpha/beta masks\n",
    "    df['TCR_full'] = df['TCRa'] + df['TCRb']\n",
    "    df['m_alpha'] = 1\n",
    "    df['m_beta'] = 1\n",
    "    df.loc[df['TCRa'] == 'X', 'm_alpha'] = 0\n",
    "    df.loc[df['TCRb'] == 'X', 'm_beta'] = 0\n",
    "\n",
    "    # Remove rows with invalid TCR_full entries\n",
    "    df = df.dropna(subset=['TCR_full'])\n",
    "    df = df[df['TCR_full'] != ' ']\n",
    "    df = df[df['TCR_full'] != 'nan']\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 2. Category builder for unseen TCR / unseen peptide / completely unseen\n",
    "# ============================================================\n",
    "\n",
    "def make_unseen_tcr_peptide_categories(\n",
    "    df_in: pd.DataFrame,\n",
    "    peptides_to_keep,\n",
    "    pct_tcr_cat1=0.02,\n",
    "    pct_tcr_cat2=0.05,\n",
    "    pct_peptide_cat3=0.01,\n",
    "    category_col='category',\n",
    "    prefix=''\n",
    "):\n",
    "    \"\"\"\n",
    "    Build three categories:\n",
    "      - completely_unseen   (unseen TCR & unseen peptide)\n",
    "      - unseen_TCR          (TCR unseen in train, peptide seen in train)\n",
    "      - unseen_peptide      (peptide unseen in train, TCR seen in train)\n",
    "\n",
    "    Returns:\n",
    "      cat1_df, cat2_df, cat3_df, remaining_df\n",
    "    \"\"\"\n",
    "    df = df_in.copy()\n",
    "\n",
    "    # -----------------------------\n",
    "    # Category 1: Completely unseen\n",
    "    # -----------------------------\n",
    "    unique_tcrs = df['TCR_full'].unique()\n",
    "    if len(unique_tcrs) == 0:\n",
    "        return (df.iloc[0:0].copy(),) * 4  # all empty\n",
    "\n",
    "    n_cat1_tcrs = max(1, int(len(unique_tcrs) * pct_tcr_cat1))\n",
    "    selected_tcrs_cat1 = set(rng.choice(unique_tcrs, size=n_cat1_tcrs, replace=False))\n",
    "\n",
    "    tcr_pairs = df[df['TCR_full'].isin(selected_tcrs_cat1)]\n",
    "    # remove peptides we insist must remain in training\n",
    "    tcr_pairs = tcr_pairs[~tcr_pairs['Peptide'].isin(peptides_to_keep)]\n",
    "\n",
    "    selected_peptides_cat1 = set(tcr_pairs['Peptide'].unique())\n",
    "    selected_tcrs_cat1 = set(tcr_pairs['TCR_full'].unique())\n",
    "\n",
    "    cat1_df = df[\n",
    "        df['TCR_full'].isin(selected_tcrs_cat1) &\n",
    "        df['Peptide'].isin(selected_peptides_cat1)\n",
    "    ].copy()\n",
    "    cat1_df[category_col] = f'{prefix}completely_unseen'\n",
    "\n",
    "    # Candidates for other categories = everything that does NOT use these TCRs OR these peptides\n",
    "    train_candidate = df[\n",
    "        ~(df['TCR_full'].isin(selected_tcrs_cat1) | df['Peptide'].isin(selected_peptides_cat1))\n",
    "    ].copy()\n",
    "\n",
    "    # -----------------------------\n",
    "    # Category 2: Unseen TCR (peptide seen)\n",
    "    # -----------------------------\n",
    "    remaining_unique_tcrs = train_candidate['TCR_full'].unique()\n",
    "    if len(remaining_unique_tcrs) > 0:\n",
    "        n_cat2_tcrs = max(1, int(len(remaining_unique_tcrs) * pct_tcr_cat2))\n",
    "        selected_tcrs_cat2 = set(\n",
    "            rng.choice(remaining_unique_tcrs, size=n_cat2_tcrs, replace=False)\n",
    "        )\n",
    "    else:\n",
    "        selected_tcrs_cat2 = set()\n",
    "\n",
    "    cat2_df = train_candidate[train_candidate['TCR_full'].isin(selected_tcrs_cat2)].copy()\n",
    "    cat2_df[category_col] = f'{prefix}unseen_TCR'\n",
    "\n",
    "    # Remove all these rows from candidate pool\n",
    "    train_candidate = train_candidate.drop(cat2_df.index)\n",
    "\n",
    "    # -----------------------------\n",
    "    # Category 3: Unseen peptide (TCR seen)\n",
    "    # -----------------------------\n",
    "    remaining_unique_peptides = train_candidate['Peptide'].unique()\n",
    "    if len(remaining_unique_peptides) > 0:\n",
    "        n_cat3_peptides = max(1, int(len(remaining_unique_peptides) * pct_peptide_cat3))\n",
    "        selected_peptides_cat3 = set(\n",
    "            rng.choice(remaining_unique_peptides, size=n_cat3_peptides, replace=False)\n",
    "        )\n",
    "        selected_peptides_cat3 = selected_peptides_cat3 - set(peptides_to_keep)\n",
    "    else:\n",
    "        selected_peptides_cat3 = set()\n",
    "\n",
    "    cat3_df = train_candidate[train_candidate['Peptide'].isin(selected_peptides_cat3)].copy()\n",
    "    cat3_df[category_col] = f'{prefix}unseen_peptide'\n",
    "\n",
    "    # Remove all rows containing these peptides from candidate pool\n",
    "    remaining_df = train_candidate.drop(cat3_df.index)\n",
    "\n",
    "    return cat1_df, cat2_df, cat3_df, remaining_df\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 3. Top-level split function\n",
    "# ============================================================\n",
    "\n",
    "def split_tcr_dataset(\n",
    "    df_raw: pd.DataFrame,\n",
    "    peptides_to_keep=PEPTIDES_TO_KEEP,\n",
    "    backbone_hlas=BACKBONE_HLAS,\n",
    "    n_test_unseen_hla=N_TEST_UNSEEN_HLA,\n",
    "    n_val_unseen_hla=N_VAL_UNSEEN_HLA,\n",
    "    min_peptides_unseen_hla_test=MIN_PEPTIDES_UNSEEN_HLA_TEST,\n",
    "    min_peptides_unseen_hla_val=MIN_PEPTIDES_UNSEEN_HLA_VAL\n",
    "):\n",
    "    \"\"\"\n",
    "    Main entry point:\n",
    "      - cleans df\n",
    "      - builds test (HLA unseen + Cat1/2/3)\n",
    "      - builds validation (HLA unseen + Cat1/2/3 on remaining)\n",
    "      - builds final train by globally removing all \"unseen\" entities\n",
    "    \"\"\"\n",
    "    df = preprocess_df(df_raw)\n",
    "\n",
    "    total_pairs = len(df)\n",
    "    print(f\"Total pairs after cleaning: {total_pairs}\")\n",
    "    print(f\"Unique TCRs: {df['TCR_full'].nunique()}\")\n",
    "    print(f\"Unique Peptides: {df['Peptide'].nunique()}\")\n",
    "    print(f\"Unique HLAs: {df['HLA'].nunique()}\")\n",
    "\n",
    "    # --------------------------------------------------------\n",
    "    # 3.1 HLA summary on full data\n",
    "    # --------------------------------------------------------\n",
    "    hla_table = df.groupby('HLA').agg(\n",
    "        TCR_full=('TCR_full', 'nunique'),\n",
    "        Peptide=('Peptide', 'nunique')\n",
    "    ).reset_index().sort_values('Peptide', ascending=False)\n",
    "\n",
    "    print(\"\\nTop HLAs by peptide count:\")\n",
    "    print(hla_table.head(10))\n",
    "\n",
    "    # --------------------------------------------------------\n",
    "    # 3.2 Choose unseen HLAs for TEST\n",
    "    # --------------------------------------------------------\n",
    "    candidate_hlas_test = set(\n",
    "        hla_table.loc[\n",
    "            (hla_table['Peptide'] >= min_peptides_unseen_hla_test) &\n",
    "            (~hla_table['HLA'].isin(backbone_hlas)),\n",
    "            'HLA'\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    if len(candidate_hlas_test) == 0:\n",
    "        print(\"\\n[WARN] No HLAs eligible for unseen-HLA TEST regime with current threshold.\")\n",
    "        test_unseen_hlas = set()\n",
    "    else:\n",
    "        n_test = min(n_test_unseen_hla, len(candidate_hlas_test))\n",
    "        test_unseen_hlas = set(\n",
    "            rng.choice(list(candidate_hlas_test), size=n_test, replace=False)\n",
    "        )\n",
    "\n",
    "    print(\"\\nTest unseen HLAs chosen:\", test_unseen_hlas)\n",
    "\n",
    "    # All rows with these HLAs go straight to test (HLA-unseen category)\n",
    "    cat0_test_df = df[df['HLA'].isin(test_unseen_hlas)].copy()\n",
    "    cat0_test_df['test_category'] = 'unseen_HLA'\n",
    "\n",
    "    # Remaining pool for test Cat1/2/3\n",
    "    pool_after_test_hla = df[~df['HLA'].isin(test_unseen_hlas)].copy()\n",
    "\n",
    "    # --------------------------------------------------------\n",
    "    # 3.3 Build Cat1/Cat2/Cat3 for TEST\n",
    "    # --------------------------------------------------------\n",
    "    cat1_test, cat2_test, cat3_test, _ = make_unseen_tcr_peptide_categories(\n",
    "        pool_after_test_hla,\n",
    "        peptides_to_keep=peptides_to_keep,\n",
    "        category_col='test_category',\n",
    "        prefix=''\n",
    "    )\n",
    "\n",
    "    print(f\"\\nTest Cat1 (completely_unseen) pairs: {len(cat1_test)}\")\n",
    "    print(f\"Test Cat2 (unseen_TCR) pairs: {len(cat2_test)}\")\n",
    "    print(f\"Test Cat3 (unseen_peptide) pairs: {len(cat3_test)}\")\n",
    "\n",
    "    other_test_df = pd.concat([cat1_test, cat2_test, cat3_test]).drop_duplicates()\n",
    "    test_df = pd.concat([cat0_test_df, other_test_df]).drop_duplicates()\n",
    "\n",
    "    print(f\"\\nTotal TEST pairs: {len(test_df)} \"\n",
    "          f\"({len(test_df) / total_pairs * 100:.2f}%)\")\n",
    "\n",
    "    # --------------------------------------------------------\n",
    "    # 3.4 Build initial dev pool (for val + future train)\n",
    "    # BUT: we will later *globally* exclude unseen entities again for train_df.\n",
    "    # For val construction, it's enough to remove test rows by index.\n",
    "    # --------------------------------------------------------\n",
    "    dev_pool = df[~df.index.isin(test_df.index)].copy()\n",
    "\n",
    "    # --------------------------------------------------------\n",
    "    # 3.5 Choose unseen HLAs for VALIDATION from dev_pool\n",
    "    # We must exclude ANY HLA that appears in test (not just test_unseen_hlas)\n",
    "    # to avoid overlap of unseen HLA regimes.\n",
    "    # --------------------------------------------------------\n",
    "    test_hlas = set(test_df['HLA'])\n",
    "\n",
    "    hla_table_dev = dev_pool.groupby('HLA').agg(\n",
    "        TCR_full=('TCR_full', 'nunique'),\n",
    "        Peptide=('Peptide', 'nunique')\n",
    "    ).reset_index()\n",
    "\n",
    "    candidate_hlas_val = set(\n",
    "        hla_table_dev.loc[\n",
    "            (hla_table_dev['Peptide'] >= min_peptides_unseen_hla_val) &\n",
    "            (~hla_table_dev['HLA'].isin(backbone_hlas)) &\n",
    "            (~hla_table_dev['HLA'].isin(test_hlas)),\n",
    "            'HLA'\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    if len(candidate_hlas_val) == 0:\n",
    "        print(\"\\n[WARN] No HLAs eligible for unseen-HLA VAL regime with current threshold.\")\n",
    "        val_unseen_hlas = set()\n",
    "    else:\n",
    "        n_val = min(n_val_unseen_hla, len(candidate_hlas_val))\n",
    "        val_unseen_hlas = set(\n",
    "            rng.choice(list(candidate_hlas_val), size=n_val, replace=False)\n",
    "        )\n",
    "\n",
    "    print(\"\\nVal unseen HLAs chosen:\", val_unseen_hlas)\n",
    "\n",
    "    cat0_val_df = dev_pool[dev_pool['HLA'].isin(val_unseen_hlas)].copy()\n",
    "    cat0_val_df['val_category'] = 'unseen_HLA'\n",
    "\n",
    "    pool_after_val_hla = dev_pool[~dev_pool['HLA'].isin(val_unseen_hlas)].copy()\n",
    "\n",
    "    # --------------------------------------------------------\n",
    "    # 3.6 Build Cat1/Cat2/Cat3 for VALIDATION\n",
    "    # --------------------------------------------------------\n",
    "    cat1_val, cat2_val, cat3_val, _ = make_unseen_tcr_peptide_categories(\n",
    "        pool_after_val_hla,\n",
    "        peptides_to_keep=peptides_to_keep,\n",
    "        category_col='val_category',\n",
    "        prefix=''\n",
    "    )\n",
    "\n",
    "    print(f\"\\nVal Cat1 (completely_unseen) pairs: {len(cat1_val)}\")\n",
    "    print(f\"Val Cat2 (unseen_TCR) pairs: {len(cat2_val)}\")\n",
    "    print(f\"Val Cat3 (unseen_peptide) pairs: {len(cat3_val)}\")\n",
    "\n",
    "    val_df = pd.concat([cat0_val_df, cat1_val, cat2_val, cat3_val]).drop_duplicates()\n",
    "\n",
    "    print(f\"\\nTotal VAL pairs: {len(val_df)} \"\n",
    "          f\"({len(val_df) / total_pairs * 100:.2f}%)\")\n",
    "\n",
    "    # --------------------------------------------------------\n",
    "    # 3.7 Build FINAL TRAIN by globally excluding all \"unseen\" entities\n",
    "    # --------------------------------------------------------\n",
    "    # TCRs/peptides used in unseen regimes must never appear in train\n",
    "\n",
    "    # Test unseen sets\n",
    "    test_cat1_tcrs = set(cat1_test['TCR_full'])\n",
    "    test_cat1_peps = set(cat1_test['Peptide'])\n",
    "\n",
    "    test_cat2_tcrs = set(cat2_test['TCR_full'])\n",
    "    test_cat3_peps = set(cat3_test['Peptide'])\n",
    "\n",
    "    # Val unseen sets\n",
    "    val_cat1_tcrs = set(cat1_val['TCR_full'])\n",
    "    val_cat1_peps = set(cat1_val['Peptide'])\n",
    "\n",
    "    val_cat2_tcrs = set(cat2_val['TCR_full'])\n",
    "    val_cat3_peps = set(cat3_val['Peptide'])\n",
    "\n",
    "    forbidden_tcrs_for_train = (\n",
    "        test_cat1_tcrs | test_cat2_tcrs |\n",
    "        val_cat1_tcrs | val_cat2_tcrs\n",
    "    )\n",
    "    forbidden_peps_for_train = (\n",
    "        test_cat1_peps | test_cat3_peps |\n",
    "        val_cat1_peps | val_cat3_peps\n",
    "    )\n",
    "    forbidden_hlas_for_train = test_unseen_hlas | val_unseen_hlas\n",
    "\n",
    "    train_df = df[\n",
    "        (~df.index.isin(test_df.index)) &\n",
    "        (~df.index.isin(val_df.index)) &\n",
    "        (~df['TCR_full'].isin(forbidden_tcrs_for_train)) &\n",
    "        (~df['Peptide'].isin(forbidden_peps_for_train)) &\n",
    "        (~df['HLA'].isin(forbidden_hlas_for_train))\n",
    "    ].copy()\n",
    "\n",
    "    print(f\"\\nTotal TRAIN pairs: {len(train_df)} \"\n",
    "          f\"({len(train_df) / total_pairs * 100:.2f}%)\")\n",
    "\n",
    "    meta = {\n",
    "        'test_unseen_hlas': test_unseen_hlas,\n",
    "        'val_unseen_hlas': val_unseen_hlas,\n",
    "        'backbone_hlas': backbone_hlas,\n",
    "    }\n",
    "\n",
    "    return train_df, val_df, test_df, meta\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 4. Sanity checks\n",
    "# ============================================================\n",
    "\n",
    "def run_sanity_checks(train_df, val_df, test_df):\n",
    "    print(\"\\n========== SANITY CHECKS ==========\")\n",
    "\n",
    "    train_tcrs = set(train_df['TCR_full'])\n",
    "    train_peps = set(train_df['Peptide'])\n",
    "\n",
    "    # --- Test categories\n",
    "    if 'test_category' in test_df.columns:\n",
    "        for cat_name, label in [\n",
    "            (\"Completely Unseen\", 'completely_unseen'),\n",
    "            (\"Unseen TCR\", 'unseen_TCR'),\n",
    "            (\"Unseen Peptide\", 'unseen_peptide')\n",
    "        ]:\n",
    "            cat = test_df[test_df['test_category'] == label]\n",
    "            tcrs = set(cat['TCR_full'])\n",
    "            peps = set(cat['Peptide'])\n",
    "\n",
    "            overlap_tcr = len(tcrs & train_tcrs)\n",
    "            overlap_pep = len(peps & train_peps)\n",
    "\n",
    "            print(f\"\\n[TEST] {cat_name} ({label})\")\n",
    "            print(f\"  #pairs: {len(cat)}\")\n",
    "            print(f\"  Overlap TCR with TRAIN: {overlap_tcr}\")\n",
    "            print(f\"  Overlap Peptide with TRAIN: {overlap_pep}\")\n",
    "\n",
    "    # --- HLA overlaps\n",
    "    train_hlas = set(train_df['HLA'])\n",
    "    val_hlas   = set(val_df['HLA'])\n",
    "    test_hlas  = set(test_df['HLA'])\n",
    "\n",
    "    print(\"\\nHLA counts:\")\n",
    "    print(\"  Train HLAs:\", len(train_hlas))\n",
    "    print(\"  Val HLAs:  \", len(val_hlas))\n",
    "    print(\"  Test HLAs: \", len(test_hlas))\n",
    "\n",
    "    unseen_hlas_test = test_hlas - train_hlas\n",
    "    unseen_hlas_val  = val_hlas - train_hlas\n",
    "\n",
    "    print(\"\\nUnseen HLAs in TEST vs TRAIN:\", unseen_hlas_test)\n",
    "    print(\"Unseen HLAs in VAL vs TRAIN:\", unseen_hlas_val)\n",
    "    print(\"Overlap of unseen-HLA between VAL and TEST:\",\n",
    "          unseen_hlas_test & unseen_hlas_val)\n",
    "\n",
    "    print(\"===================================\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "05d6cd4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total pairs after cleaning: 39926\n",
      "Unique TCRs: 36197\n",
      "Unique Peptides: 1457\n",
      "Unique HLAs: 71\n",
      "\n",
      "Top HLAs by peptide count:\n",
      "               HLA  TCR_full  Peptide\n",
      "1      HLA-A*02:01     12012      864\n",
      "0      HLA-A*01:01      1961      122\n",
      "23     HLA-B*07:02      1861      107\n",
      "15     HLA-A*24:02       736       89\n",
      "25     HLA-B*08:01      2114       59\n",
      "3   HLA-A*02:01:48        40       35\n",
      "29     HLA-B*27:05        24       31\n",
      "32     HLA-B*35:01        60       22\n",
      "54     HLA-B*57:03         1       22\n",
      "12     HLA-A*11:01      2344       18\n",
      "\n",
      "Test unseen HLAs chosen: {np.str_('HLA-A*02:01:48'), np.str_('HLA-B*57:03')}\n",
      "\n",
      "Test Cat1 (completely_unseen) pairs: 116\n",
      "Test Cat2 (unseen_TCR) pairs: 1866\n",
      "Test Cat3 (unseen_peptide) pairs: 33\n",
      "\n",
      "Total TEST pairs: 2097 (5.25%)\n",
      "\n",
      "[WARN] No HLAs eligible for unseen-HLA VAL regime with current threshold.\n",
      "\n",
      "Val unseen HLAs chosen: set()\n",
      "\n",
      "Val Cat1 (completely_unseen) pairs: 121\n",
      "Val Cat2 (unseen_TCR) pairs: 1752\n",
      "Val Cat3 (unseen_peptide) pairs: 26\n",
      "\n",
      "Total VAL pairs: 1899 (4.76%)\n",
      "\n",
      "Total TRAIN pairs: 34198 (85.65%)\n",
      "\n",
      "========== SANITY CHECKS ==========\n",
      "\n",
      "[TEST] Completely Unseen (completely_unseen)\n",
      "  #pairs: 116\n",
      "  Overlap TCR with TRAIN: 0\n",
      "  Overlap Peptide with TRAIN: 0\n",
      "\n",
      "[TEST] Unseen TCR (unseen_TCR)\n",
      "  #pairs: 1866\n",
      "  Overlap TCR with TRAIN: 0\n",
      "  Overlap Peptide with TRAIN: 190\n",
      "\n",
      "[TEST] Unseen Peptide (unseen_peptide)\n",
      "  #pairs: 33\n",
      "  Overlap TCR with TRAIN: 3\n",
      "  Overlap Peptide with TRAIN: 0\n",
      "\n",
      "HLA counts:\n",
      "  Train HLAs: 58\n",
      "  Val HLAs:   27\n",
      "  Test HLAs:  35\n",
      "\n",
      "Unseen HLAs in TEST vs TRAIN: {'HLA-C*12:02', 'HLA-A*02:01:48', 'HLA-B*35:08:01', 'HLA-B*81:01', 'HLA-B*39:01', 'HLA-B*42:01', 'HLA-C*08:02:12', 'HLA-B*37:01', 'HLA-B*57:03'}\n",
      "Unseen HLAs in VAL vs TRAIN: {'HLA-B*37:01'}\n",
      "Overlap of unseen-HLA between VAL and TEST: {'HLA-B*37:01'}\n",
      "===================================\n",
      "\n",
      "Meta: {'test_unseen_hlas': {np.str_('HLA-A*02:01:48'), np.str_('HLA-B*57:03')}, 'val_unseen_hlas': set(), 'backbone_hlas': {'HLA-A*02:01', 'HLA-B*07:02', 'HLA-B*08:01', 'HLA-A*03:01', 'HLA-A*01:01', 'HLA-A*11:01', 'HLA-A*24:02'}}\n"
     ]
    }
   ],
   "source": [
    "train_df, val_df, test_df, meta = split_tcr_dataset(df)\n",
    "\n",
    "run_sanity_checks(train_df, val_df, test_df)\n",
    "print(\"Meta:\", meta)\n",
    "\n",
    "# save to data\n",
    "train_df.to_csv(TRAIN_DIR / 'train_df.csv', index=False)\n",
    "val_df.to_csv(VAL_DIR / 'val_df.csv', index=False)\n",
    "test_df.to_csv(TEST_DIR / 'test_df.csv', index=False)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc76180c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MSA Building and YAML generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66e6fea7",
   "metadata": {},
   "source": [
    "#### Old Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ad2a96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total pairs: 39926\n",
      "Unique TCRs: 36197\n",
      "Unique Peptides: 1457\n",
      "Unique HLAs: 71\n",
      "Avg. peptides per TCR: 1.10\n",
      "Avg. TCRs per Peptide: 27.40\n",
      "                  HLA  TCR_full  Peptide\n",
      "0         HLA-A*01:01      1961      122\n",
      "1         HLA-A*02:01     12012      864\n",
      "2     HLA-A*02:01:110         1        1\n",
      "3      HLA-A*02:01:48        40       35\n",
      "4      HLA-A*02:01:59         2        2\n",
      "5      HLA-A*02:01:98         2        2\n",
      "6         HLA-A*02:05        22        3\n",
      "7         HLA-A*02:06         6        3\n",
      "8   HLA-A*02:06:01:03         1        1\n",
      "9        HLA-A*02:266         1        1\n",
      "10        HLA-A*03:01     14831       18\n",
      "11        HLA-A*08:01        64        1\n",
      "12        HLA-A*11:01      2344       18\n",
      "13     HLA-A*11:01:18         1        2\n",
      "14        HLA-A*24:01        74        2\n",
      "15        HLA-A*24:02       736       89\n",
      "16     HLA-A*24:02:33         1        1\n",
      "17     HLA-A*24:02:84         2        3\n",
      "18        HLA-A*25:01         1        1\n",
      "19        HLA-A*29:02         5        6\n",
      "20        HLA-A*30:02         4        2\n",
      "21        HLA-A*68:01       185        3\n",
      "22        HLA-A*68:02         2        1\n",
      "23        HLA-B*07:02      1861      107\n",
      "24     HLA-B*07:02:48         3        2\n",
      "25        HLA-B*08:01      2114       59\n",
      "26     HLA-B*08:01:29         4        2\n",
      "27        HLA-B*15:01       225        7\n",
      "28        HLA-B*18:01        13        7\n",
      "29        HLA-B*27:05        24       31\n",
      "30     HLA-B*27:05:31         1        2\n",
      "31        HLA-B*27:09         2        2\n",
      "32        HLA-B*35:01        60       22\n",
      "33     HLA-B*35:01:45         1        1\n",
      "34        HLA-B*35:03         6        2\n",
      "35        HLA-B*35:08        18       18\n",
      "36     HLA-B*35:08:01         4        3\n",
      "37     HLA-B*35:42:01         4        5\n",
      "38     HLA-B*35:42:02         1        2\n",
      "39        HLA-B*37:01        91        3\n",
      "40     HLA-B*37:01:10         1        1\n",
      "41        HLA-B*38:01         5        4\n",
      "42        HLA-B*39:01         2        1\n",
      "43        HLA-B*40:01        96        4\n",
      "44        HLA-B*41:02         2        3\n",
      "45        HLA-B*42:01         1        1\n",
      "46        HLA-B*44:02        42        6\n",
      "47        HLA-B*44:03         3        2\n",
      "48        HLA-B*44:05         4        3\n",
      "49     HLA-B*44:05:01         2        3\n",
      "50        HLA-B*50:01         1        1\n",
      "51        HLA-B*51:01        30        3\n",
      "52       HLA-B*51:193         1        1\n",
      "53        HLA-B*57:01       136       12\n",
      "54        HLA-B*57:03         1       22\n",
      "55        HLA-B*57:06         1        1\n",
      "56        HLA-B*81:01         1        1\n",
      "57        HLA-C*01:02         3        2\n",
      "58        HLA-C*03:03         5        4\n",
      "59        HLA-C*03:04         7        3\n",
      "60        HLA-C*04:01         2        2\n",
      "61        HLA-C*05:01         5        4\n",
      "62        HLA-C*06:02         4        3\n",
      "63        HLA-C*07:01         4        3\n",
      "64        HLA-C*07:02         3        3\n",
      "65        HLA-C*08:02         7        4\n",
      "66     HLA-C*08:02:12         1        1\n",
      "67        HLA-C*12:02         2        2\n",
      "68        HLA-C*14:02         1        1\n",
      "69  HLA-E*01:01:01:03         2        2\n",
      "70        HLA-E*01:03       359        7\n",
      "Test HLA candidates: {'HLA-A*08:01', 'HLA-E*01:03', 'HLA-B*40:01', 'HLA-B*57:01', 'HLA-A*24:02', 'HLA-B*37:01', 'HLA-B*57:03', 'HLA-A*24:01', 'HLA-B*18:01', 'HLA-B*35:01', 'HLA-A*68:01', 'HLA-B*15:01', 'HLA-A*02:05', 'HLA-B*51:01', 'HLA-B*44:02', 'HLA-B*07:02', 'HLA-B*38:01', 'HLA-B*27:05', 'HLA-B*08:01', 'HLA-A*01:01', 'HLA-A*11:01', 'HLA-A*02:01:48', 'HLA-B*35:08'}\n",
      "Category 1 (completely unseen) pairs: 124\n",
      "Unique HLAs in Category 1: 15\n",
      "Category 2 (unseen TCR) pairs: 1842\n",
      "Unique HLAs in Category 2: 22\n",
      "Category 3 (unseen peptide) pairs: 37\n",
      "Unique HLAs in Category 3: 6\n",
      "Unique HLAs in test set: 29\n",
      "Unique HLAs in final train set: 65\n",
      "Overlapping HLAs between train and test: 27\n",
      "\n",
      "Final Split:\n",
      "Training set: 36740 pairs (92.02%)\n",
      "Test set (other): 2003 pairs (5.02%)\n",
      "\n",
      "Running Validation Tests...\n",
      "\n",
      "Category 1: Completely Unseen Pairs\n",
      "Overlapping TCRs in training: 0 (should be 0)\n",
      "Overlapping Peptides in training: 0 (should be 0)\n",
      "\n",
      "Category 2: Unseen TCR but Seen Peptide\n",
      "Overlapping TCRs in training: 0 (should be 0)\n",
      "Overlapping Peptides in training: 207 (should be > 0)\n",
      "\n",
      "Category 3: Unseen Peptide but Seen TCR\n",
      "Overlapping TCRs in training: 4 (should be > 0)\n",
      "Overlapping Peptides in training: 0 (should be 0)\n"
     ]
    }
   ],
   "source": [
    "# separate into train, val and test\n",
    "# taken from data_test_val_split.py (IMMREP2025 folder)\n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "\n",
    "# 1. Fill empty/nan values with <unk> token\n",
    "df['TCRa'] = df['TCRa'].fillna('X')\n",
    "df['TCRb'] = df['TCRb'].fillna('X')\n",
    "\n",
    "# Replace empty strings with <unk>\n",
    "df.loc[df['TCRa'] == '', 'TCRa'] = 'X'\n",
    "df.loc[df['TCRb'] == '', 'TCRb'] = 'X'\n",
    "\n",
    "df['TCR_full'] = df['TCRa'] + df['TCRb']\n",
    "df['m_alpha'] = 1\n",
    "df['m_beta'] = 1\n",
    "df.loc[df['TCRa'] == 'X', 'm_alpha'] = 0\n",
    "df.loc[df['TCRb'] == 'X', 'm_beta'] = 0\n",
    "\n",
    "# Remove rows with invalid TCR_full entries\n",
    "df = df.dropna(subset=['TCR_full'])\n",
    "df = df[df['TCR_full'] != ' ']\n",
    "df = df[df['TCR_full'] != 'nan']\n",
    "\n",
    "# # Calculate the number of peptides per TCR\n",
    "# peptides_per_tcr = df.groupby('TCR_full')['Peptide'].nunique().reset_index(name='peptide_count')\n",
    "\n",
    "# # Calculate the number of TCRs per peptide\n",
    "# tcrs_per_peptide = df.groupby('Peptide')['TCR_full'].nunique().reset_index(name='tcr_count')\n",
    "\n",
    "\n",
    "# print(peptides_per_tcr.head(3), tcrs_per_peptide.head(3))\n",
    "\n",
    "# potentially need to separate HLAs as well? \n",
    "\n",
    "\n",
    "# ------------------------------\n",
    "# 2. Overview of the Dataset\n",
    "# ------------------------------\n",
    "\n",
    "# how many unique peptides, tcrs and hla\n",
    "total_pairs = len(df)\n",
    "unique_tcrs = set(df['TCR_full'])\n",
    "unique_peptides = set(df['Peptide'])\n",
    "num_unique_tcrs = len(unique_tcrs)\n",
    "num_unique_peptides = len(unique_peptides)\n",
    "num_unique_hlas = len(set(df['HLA']))\n",
    "\n",
    "\n",
    "print(f\"Total pairs: {total_pairs}\")\n",
    "print(f\"Unique TCRs: {num_unique_tcrs}\")\n",
    "print(f\"Unique Peptides: {num_unique_peptides}\")\n",
    "print(f\"Unique HLAs: {num_unique_hlas}\")\n",
    "\n",
    "#number_of_peptides_per_hla = df.groupby('HLA')['Peptide'].nunique().reset_index(name='peptide_count')\n",
    "avg_peptides_per_tcr = total_pairs / num_unique_tcrs\n",
    "avg_tcrs_per_peptide = total_pairs / num_unique_peptides\n",
    "#number_of_tcrs_per_hla = df.groupby('HLA')['TCR_full'].nunique().reset_index(name='tcr_count')\n",
    "#hlas = number_of_tcrs_per_hla.merge(number_of_peptides_per_hla, on='HLA', how='left')\n",
    "hlas = df.groupby('HLA').agg({'TCR_full': 'nunique', 'Peptide': 'nunique'}).reset_index()\n",
    "\n",
    "print(f\"Avg. peptides per TCR: {avg_peptides_per_tcr:.2f}\")\n",
    "print(f\"Avg. TCRs per Peptide: {avg_tcrs_per_peptide:.2f}\")\n",
    "#print(number_of_peptides_per_hla.head(10))\n",
    "#print(number_of_tcrs_per_hla.head(10))\n",
    "print(hlas.head(71))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# data_for_other_cats = combined_df[~combined_df['HLA'].isin(selected_hlas_cat0)]\n",
    "data_for_other_cats = df.copy()\n",
    "\n",
    "# Define a list of peptides that must remain in training (if desired)\n",
    "peptides_to_keep = [\n",
    "    \"KLGGALQAK\", \"GILGFVFTL\", \"AVFDRKSDAK\", \"RAKFKQLL\", \"SPRWYFYYL\",\n",
    "    \"YLQPRTFLL\", \"TTDPSFLGRY\", \"GLCTLVAML\", \"RVRAYTYSK\", \"IVTDFSVIK\",\n",
    "    \"LLWNGPMAV\", \"LLLDRLNQL\", \"NLVPMVATV\", \"LLAGIGTVPI\", \"RLRAEAQVK\",\n",
    "    \"ELAGIGILTV\", \"YVLDHLIVV\", \"LTDEMIAQY\", \"CINGVCWTV\", \"TPRVTGGGAM\",\n",
    "    \"VMATRRNVL\", \"KTFPPTEPK\", \"QYIKWPWYI\", \"DATYQRTRALVR\", \"NQKLIANQF\",\n",
    "    \"FLRGRAYGL\", \"CTELKLSDY\", \"ATDALMTGF\", \"RPPIFIRRL\", \"NYNYLYRLF\",\n",
    "    \"FLYALALLL\", \"VMTTVLATL\", \"CLGGLLTMV\", \"KSKRTPMGF\", \"RPHERNGFTVL\",\n",
    "    \"MEVTPSGTWL\", \"FTSDYYQLY\", \"RPIIRPATL\", \"ALAGIGILTV\", \"LLYDANYFL\",\n",
    "    \"HPVTKYIM\", \"RLPGVLPRA\", \"RFPLTFGWCF\", \"VYFLQSINF\", \"PTDNYITTY\",\n",
    "    \"ALWEIQQVV\", \"QAKWRLQTL\", \"RTATKQYNV\", \"LLFGYPVYV\"\n",
    "]\n",
    "\n",
    "\n",
    "# --- Category 1: Completely Unseen Pairs ---\n",
    "# Choose percentages for unique TCRs and peptides (start with 2% each)\n",
    "pct_tcr_cat1 = 0.02\n",
    "pct_peptide_cat1 = 0.02\n",
    "\n",
    "unique_tcrs = set(data_for_other_cats['TCR_full'])\n",
    "num_unique_tcrs = len(unique_tcrs)\n",
    "selected_tcrs_cat1 = set(np.random.choice(list(unique_tcrs), size=int(num_unique_tcrs * pct_tcr_cat1), replace=False))\n",
    "\n",
    "# Get all pairs that involve the selected TCRs\n",
    "tcr_pairs = data_for_other_cats[data_for_other_cats['TCR_full'].isin(selected_tcrs_cat1)]\n",
    "# Optionally, remove pairs with peptides we want to keep\n",
    "tcr_pairs = tcr_pairs[~tcr_pairs['Peptide'].isin(peptides_to_keep)]\n",
    "\n",
    "# Derive the set of peptides from these pairs\n",
    "selected_peptides_cat1 = set(tcr_pairs['Peptide'].unique())\n",
    "# Update the TCR set to only those that remain after filtering\n",
    "selected_tcrs_cat1 = set(tcr_pairs['TCR_full'].unique())\n",
    "\n",
    "# Category 1: Define as all pairs where BOTH the TCR is in selected_tcrs_cat1\n",
    "# AND the peptide is in selected_peptides_cat1\n",
    "cat1_df = data_for_other_cats[\n",
    "    data_for_other_cats['TCR_full'].isin(selected_tcrs_cat1) &\n",
    "    data_for_other_cats['Peptide'].isin(selected_peptides_cat1)\n",
    "].copy()\n",
    "cat1_df['test_category'] = 'completely_unseen'\n",
    "cat1_df.loc[cat1_df['TCR_full'].str.startswith('<unk>'), 'test_category'] = 'completely_unseen_unknownalpha'\n",
    "cat1_df.loc[cat1_df['TCR_full'].str.endswith('<unk>'), 'test_category'] = 'completely_unseen_unknownbeta'\n",
    "\n",
    "print(\"Category 1 (completely unseen) pairs:\", len(cat1_df))\n",
    "\n",
    "# print how many unique hlas are in cat1\n",
    "unique_hlas_cat1 = set(cat1_df['HLA'])\n",
    "print(f\"Unique HLAs in Category 1: {len(unique_hlas_cat1)}\")#,\n",
    "        #'Unique HLAs in cat1', unique_hlas_cat1)\n",
    "\n",
    "# Now, to ensure these TCRs and peptides do not appear anywhere in training,\n",
    "# define the training candidate as all rows that do NOT contain any selected TCR or selected peptide.\n",
    "train_candidate = data_for_other_cats[\n",
    "    ~(data_for_other_cats['TCR_full'].isin(selected_tcrs_cat1) | data_for_other_cats['Peptide'].isin(selected_peptides_cat1))\n",
    "]\n",
    "\n",
    "# ------------------------------\n",
    "# --- Category 2: Unseen TCR but Seen Peptide ---\n",
    "# From train_candidate, select a percentage of unique TCRs (e.g., 5%)\n",
    "remaining_unique_tcrs = set(train_candidate['TCR_full'])\n",
    "pct_tcr_cat2 = 0.05\n",
    "selected_tcrs_cat2 = set(np.random.choice(list(remaining_unique_tcrs), size=int(len(remaining_unique_tcrs) * pct_tcr_cat2), replace=False))\n",
    "\n",
    "cat2_df = train_candidate[train_candidate['TCR_full'].isin(selected_tcrs_cat2)].copy()\n",
    "# Add more specific tags for TCRs with unknown regions\n",
    "cat2_df['test_category'] = 'unseen_TCR'\n",
    "cat2_df.loc[cat2_df['TCR_full'].str.startswith('<unk>'), 'test_category'] = 'unseen_TCR_unknownalpha'\n",
    "cat2_df.loc[cat2_df['TCR_full'].str.endswith('<unk>'), 'test_category'] = 'unseen_TCR_unknownbeta'\n",
    "\n",
    "print(\"Category 2 (unseen TCR) pairs:\", len(cat2_df))\n",
    "\n",
    "# print how many unique hlas are in cat2\n",
    "unique_hlas_cat2 = set(cat2_df['HLA'])\n",
    "print(f\"Unique HLAs in Category 2: {len(unique_hlas_cat2)}\")#,\n",
    "        #'Unique HLAs in cat2', unique_hlas_cat2)\n",
    "\n",
    "# Remove Category 2 pairs from train_candidate\n",
    "train_candidate = train_candidate.drop(cat2_df.index)\n",
    "\n",
    "# ------------------------------\n",
    "# --- Category 3: Unseen Peptide but Seen TCR ---\n",
    "# From train_candidate, select a percentage of unique peptides (e.g., 1%)\n",
    "remaining_unique_peptides = set(train_candidate['Peptide'])\n",
    "pct_peptide_cat3 = 0.01\n",
    "selected_peptides_cat3 = set(np.random.choice(list(remaining_unique_peptides), size=int(len(remaining_unique_peptides) * pct_peptide_cat3), replace=False))\n",
    "# Remove any peptides that need to be kept in training from the selected peptides\n",
    "selected_peptides_cat3 = selected_peptides_cat3 - set(peptides_to_keep)\n",
    "\n",
    "cat3_df = train_candidate[train_candidate['Peptide'].isin(selected_peptides_cat3)].copy()\n",
    "\n",
    "cat3_df['test_category'] = 'unseen_peptide'\n",
    "print(\"Category 3 (unseen peptide) pairs:\", len(cat3_df))\n",
    "\n",
    "# print how many unique hlas are in cat3\n",
    "unique_hlas_cat3 = set(cat3_df['HLA'])\n",
    "print(f\"Unique HLAs in Category 3: {len(unique_hlas_cat3)}\")#,\n",
    "        #'Unique HLAs in cat3', unique_hlas_cat3)\n",
    "\n",
    "# Combine all test categories except unseen_HLA\n",
    "other_test_df = pd.concat([cat1_df, cat2_df, cat3_df])\n",
    "other_test_df = other_test_df.drop_duplicates()\n",
    "unique_hlas_other_test = set(other_test_df['HLA'])\n",
    "print(f\"Unique HLAs in test set: {len(unique_hlas_other_test)}\")#,\n",
    "        #'Unique HLAs in test set', unique_hlas_other_test)\n",
    "\n",
    "# Final training set is the remainder of data_for_other_cats that does NOT contain any TCR or peptide selected for Category 1,\n",
    "# AND also does not contain the pairs selected for Categories 2 and 3.\n",
    "final_train_df = train_candidate.drop(cat3_df.index)\n",
    "\n",
    "# Alternatively, if you want to be sure no overlap exists:\n",
    "final_train_df = data_for_other_cats[\n",
    "    ~(data_for_other_cats['TCR_full'].isin(selected_tcrs_cat1) |\n",
    "      data_for_other_cats['Peptide'].isin(selected_peptides_cat1) |\n",
    "      data_for_other_cats['TCR_full'].isin(selected_tcrs_cat2) |\n",
    "      data_for_other_cats['Peptide'].isin(selected_peptides_cat3))\n",
    "]\n",
    "unique_hlas_final_train = set(final_train_df['HLA'])\n",
    "print(f\"Unique HLAs in final train set: {len(unique_hlas_final_train)}\")#,\n",
    "        #'Unique HLAs in final train set', unique_hlas_final_train)\n",
    "\n",
    "# overlapping hlas between train and test\n",
    "overlapping_hlas = unique_hlas_final_train.intersection(unique_hlas_other_test)\n",
    "print(f\"Overlapping HLAs between train and test: {len(overlapping_hlas)}\")#,\n",
    "        #'Overlapping HLAs', overlapping_hlas)\n",
    "\n",
    "\n",
    "print(f\"\\nFinal Split:\")\n",
    "print(f\"Training set: {len(final_train_df)} pairs ({len(final_train_df) / total_pairs * 100:.2f}%)\")\n",
    "#print(f\"Test set (unseen HLA): {len(cat0_df)} pairs ({len(cat0_df) / total_pairs * 100:.2f}%)\")\n",
    "print(f\"Test set (other): {len(other_test_df)} pairs ({len(other_test_df) / total_pairs * 100:.2f}%)\")\n",
    "\n",
    "\n",
    "# Create sets from the final training set for lookup\n",
    "train_tcr_set = set(final_train_df['TCR_full'])\n",
    "train_peptide_set = set(final_train_df['Peptide'])\n",
    "\n",
    "print(\"\\nRunning Validation Tests...\")\n",
    "\n",
    "# Test Case 1: Completely Unseen Pairs (Category: 'completely_unseen')\n",
    "cat1 = other_test_df[other_test_df['test_category'] == 'completely_unseen']\n",
    "cat1_tcrs = set(cat1['TCR_full'])\n",
    "cat1_peptides = set(cat1['Peptide'])\n",
    "overlap_tcr_cat1 = cat1_tcrs.intersection(train_tcr_set)\n",
    "overlap_peptides_cat1 = cat1_peptides.intersection(train_peptide_set)\n",
    "\n",
    "print(\"\\nCategory 1: Completely Unseen Pairs\")\n",
    "print(f\"Overlapping TCRs in training: {len(overlap_tcr_cat1)} (should be 0)\")\n",
    "print(f\"Overlapping Peptides in training: {len(overlap_peptides_cat1)} (should be 0)\")\n",
    "assert len(overlap_tcr_cat1) == 0, \"Error: Some TCRs in 'completely_unseen' category are in training!\"\n",
    "assert len(overlap_peptides_cat1) == 0, \"Error: Some peptides in 'completely_unseen' category are in training!\"\n",
    "\n",
    "# Test Case 2: Unseen TCR but Seen Peptide (Category: 'unseen_TCR')\n",
    "cat2 = other_test_df[other_test_df['test_category'] == 'unseen_TCR']\n",
    "cat2_tcrs = set(cat2['TCR_full'])\n",
    "cat2_peptides = set(cat2['Peptide'])\n",
    "overlap_tcr_cat2 = cat2_tcrs.intersection(train_tcr_set)\n",
    "overlap_peptides_cat2 = cat2_peptides.intersection(train_peptide_set)\n",
    "\n",
    "print(\"\\nCategory 2: Unseen TCR but Seen Peptide\")\n",
    "print(f\"Overlapping TCRs in training: {len(overlap_tcr_cat2)} (should be 0)\")\n",
    "print(f\"Overlapping Peptides in training: {len(overlap_peptides_cat2)} (should be > 0)\")\n",
    "assert len(overlap_tcr_cat2) == 0, \"Error: Some TCRs in 'unseen_TCR' category are in training!\"\n",
    "assert len(overlap_peptides_cat2) > 0, \"Error: No peptides in 'unseen_TCR' category are in training!\"\n",
    "\n",
    "# Test Case 3: Unseen Peptide but Seen TCR (Category: 'unseen_peptide')\n",
    "cat3 = other_test_df[other_test_df['test_category'] == 'unseen_peptide']\n",
    "cat3_tcrs = set(cat3['TCR_full'])\n",
    "cat3_peptides = set(cat3['Peptide'])\n",
    "overlap_tcr_cat3 = cat3_tcrs.intersection(train_tcr_set)\n",
    "overlap_peptides_cat3 = cat3_peptides.intersection(train_peptide_set)\n",
    "\n",
    "print(\"\\nCategory 3: Unseen Peptide but Seen TCR\")\n",
    "print(f\"Overlapping TCRs in training: {len(overlap_tcr_cat3)} (should be > 0)\")\n",
    "print(f\"Overlapping Peptides in training: {len(overlap_peptides_cat3)} (should be 0)\")\n",
    "assert len(overlap_peptides_cat3) == 0, \"Error: Some peptides in 'unseen_peptide' category are in training!\"\n",
    "assert len(overlap_tcr_cat3) > 0, \"Error: No TCRs in 'unseen_peptide' category are in training!\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb1cc6cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Further split train into train and val\n",
    "train_df, val_df = train_test_split(final_train_df, test_size=0.1, random_state=42)\n",
    "\n",
    "# Save the splits\n",
    "# train_df.to_csv(TRAIN_DIR / \"train.csv\", index=False)\n",
    "# val_df.to_csv(VAL_DIR / \"val.csv\", index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "165d9148",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "# # ------------------------------\n",
    "# # 1. Data Loading & Preprocessing\n",
    "# # ------------------------------\n",
    "\n",
    "# # Read the input files\n",
    "# iedb_df = pd.read_csv('iedb_positives.csv')\n",
    "# vdjdb_df = pd.read_csv('vdjdb_positives.csv')\n",
    "\n",
    "# # Add source column to each dataframe\n",
    "# iedb_df['source'] = 'iedb'\n",
    "# vdjdb_df['source'] = 'vdjdb'\n",
    "\n",
    "# # Combine TCRa and TCRb columns to form a unique TCR identifier\n",
    "# # Fill empty/nan values with <unk> token\n",
    "# iedb_df['TCRa'] = iedb_df['TCRa'].fillna('<unk>')\n",
    "# iedb_df['TCRb'] = iedb_df['TCRb'].fillna('<unk>')\n",
    "# vdjdb_df['TCRa'] = vdjdb_df['TCRa'].fillna('<unk>')\n",
    "# vdjdb_df['TCRb'] = vdjdb_df['TCRb'].fillna('<unk>')\n",
    "\n",
    "# # Replace empty strings with <unk>\n",
    "# iedb_df.loc[iedb_df['TCRa'] == '', 'TCRa'] = '<unk>'\n",
    "# iedb_df.loc[iedb_df['TCRb'] == '', 'TCRb'] = '<unk>'\n",
    "# vdjdb_df.loc[vdjdb_df['TCRa'] == '', 'TCRa'] = '<unk>'\n",
    "# vdjdb_df.loc[vdjdb_df['TCRb'] == '', 'TCRb'] = '<unk>'\n",
    "\n",
    "# # iedb_df['TCR_full'] = iedb_df['TCRa'] + '<sep>' +  iedb_df['TCRb']\n",
    "# # vdjdb_df['TCR_full'] = vdjdb_df['TCRa'] + '<sep>' + vdjdb_df['TCRb']\n",
    "\n",
    "# iedb_df['TCR_full'] = iedb_df['TCRa'] + iedb_df['TCRb']\n",
    "# vdjdb_df['TCR_full'] = vdjdb_df['TCRa'] + vdjdb_df['TCRb']\n",
    "\n",
    "# # Combine both datasets\n",
    "# combined_df = pd.concat([iedb_df, vdjdb_df], ignore_index=True)\n",
    "\n",
    "# # Remove rows with invalid TCR_full entries\n",
    "# combined_df = combined_df.dropna(subset=['TCR_full'])\n",
    "# combined_df = combined_df[combined_df['TCR_full'] != ' ']\n",
    "# combined_df = combined_df[combined_df['TCR_full'] != 'nan']\n",
    "\n",
    "# #uknowqn - <unk>\n",
    "# # separation <sep>\n",
    "# # TCR vs peptide token - if need to add for just 1 model\n",
    "\n",
    "# # ------------------------------\n",
    "# # Plot histograms of data\n",
    "# # Plot histograms\n",
    "# # Calculate the number of peptides per TCR\n",
    "# peptides_per_tcr = combined_df.groupby('TCR_full')['Peptide'].nunique().reset_index(name='peptide_count')\n",
    "\n",
    "# # Calculate the number of TCRs per peptide\n",
    "# tcrs_per_peptide = combined_df.groupby('Peptide')['TCR_full'].nunique().reset_index(name='tcr_count')\n",
    "\n",
    "\n",
    "# # Plot histogram for peptides per TCR\n",
    "# plt.figure(figsize=(10, 5))\n",
    "# max_peptides = peptides_per_tcr['peptide_count'].max()\n",
    "# print(f\"Max peptides per TCR: {max_peptides}\")\n",
    "# sns.histplot(peptides_per_tcr['peptide_count'], bins=30)\n",
    "# plt.xlabel(\"Number of Peptides per TCR\")\n",
    "# plt.ylabel(\"Number of TCRs\")\n",
    "# plt.title(\"Distribution of Peptides per TCR\")\n",
    "# plt.xlim(0, min(max_peptides, peptides_per_tcr['peptide_count'].quantile(0.99)))\n",
    "# #plt.show()\n",
    "# plt.savefig('Peptides_per_TCR.png')\n",
    "\n",
    "# # Plot histogram for TCRs per peptide  \n",
    "# plt.figure(figsize=(10, 5))\n",
    "# max_tcrs = tcrs_per_peptide['tcr_count'].max()\n",
    "# print(f\"Max TCRs per peptide: {max_tcrs}\")\n",
    "# sns.histplot(tcrs_per_peptide['tcr_count'], bins=100, color='orange')\n",
    "# plt.xlabel(\"Number of TCRs per Peptide\")\n",
    "# plt.ylabel(\"Number of Peptides\")\n",
    "# plt.title(\"Distribution of TCRs per Peptide\")\n",
    "# plt.xlim(0, min(max_tcrs, tcrs_per_peptide['tcr_count'].mean() + 3 * tcrs_per_peptide['tcr_count'].std()))\n",
    "# #plt.show()\n",
    "# plt.savefig('TCRs_per_pepdite.png')\n",
    "\n",
    "\n",
    "# ------------------------------\n",
    "# 2. Overview of the Dataset\n",
    "# ------------------------------\n",
    "\n",
    "total_pairs = len(combined_df)\n",
    "unique_tcrs = set(combined_df['TCR_full'])\n",
    "unique_peptides = set(combined_df['Peptide'])\n",
    "num_unique_tcrs = len(unique_tcrs)\n",
    "num_unique_peptides = len(unique_peptides)\n",
    "\n",
    "print(f\"Total pairs: {total_pairs}\")\n",
    "print(f\"Unique TCRs: {num_unique_tcrs}\")\n",
    "print(f\"Unique Peptides: {num_unique_peptides}\")\n",
    "\n",
    "avg_peptides_per_tcr = total_pairs / num_unique_tcrs\n",
    "avg_tcrs_per_peptide = total_pairs / num_unique_peptides\n",
    "\n",
    "print(f\"Avg. peptides per TCR: {avg_peptides_per_tcr:.2f}\")\n",
    "print(f\"Avg. TCRs per Peptide: {avg_tcrs_per_peptide:.2f}\")\n",
    "\n",
    "# ------------------------------\n",
    "# 3. Data Splitting: Create Test Categories\n",
    "# ------------------------------\n",
    "\n",
    "# Print the number of unique HLAs at the start\n",
    "unique_hlas = set(combined_df['HLA'])\n",
    "num_unique_hlas = len(unique_hlas)\n",
    "print(f\"Number of unique HLAs: {num_unique_hlas}\")\n",
    "\n",
    "# Select 5 HLAs for unseen_HLA (or all if fewer)\n",
    "num_hlas_to_select = min(5, num_unique_hlas)\n",
    "if num_unique_hlas < 5:\n",
    "    print(f\"Warning: Only {num_unique_hlas} unique HLAs available, using all for unseen_HLA category.\")\n",
    "selected_hlas_cat0 = set(np.random.choice(list(unique_hlas), size=num_hlas_to_select, replace=False))\n",
    "\n",
    "cat0_df = combined_df[combined_df['HLA'].isin(selected_hlas_cat0)].copy()\n",
    "cat0_df['test_category'] = 'unseen_HLA'\n",
    "print(f\"Category 0 (unseen HLA) pairs: {len(cat0_df)}\")\n",
    "\n",
    "# Remove these from the pool before any other split\n",
    "data_for_other_cats = combined_df[~combined_df['HLA'].isin(selected_hlas_cat0)]\n",
    "\n",
    "# Define a list of peptides that must remain in training (if desired)\n",
    "peptides_to_keep = [\n",
    "    \"KLGGALQAK\", \"GILGFVFTL\", \"AVFDRKSDAK\", \"RAKFKQLL\", \"SPRWYFYYL\",\n",
    "    \"YLQPRTFLL\", \"TTDPSFLGRY\", \"GLCTLVAML\", \"RVRAYTYSK\", \"IVTDFSVIK\",\n",
    "    \"LLWNGPMAV\", \"LLLDRLNQL\", \"NLVPMVATV\", \"LLAGIGTVPI\", \"RLRAEAQVK\",\n",
    "    \"ELAGIGILTV\", \"YVLDHLIVV\", \"LTDEMIAQY\", \"CINGVCWTV\", \"TPRVTGGGAM\",\n",
    "    \"VMATRRNVL\", \"KTFPPTEPK\", \"QYIKWPWYI\", \"DATYQRTRALVR\", \"NQKLIANQF\",\n",
    "    \"FLRGRAYGL\", \"CTELKLSDY\", \"ATDALMTGF\", \"RPPIFIRRL\", \"NYNYLYRLF\",\n",
    "    \"FLYALALLL\", \"VMTTVLATL\", \"CLGGLLTMV\", \"KSKRTPMGF\", \"RPHERNGFTVL\",\n",
    "    \"MEVTPSGTWL\", \"FTSDYYQLY\", \"RPIIRPATL\", \"ALAGIGILTV\", \"LLYDANYFL\",\n",
    "    \"HPVTKYIM\", \"RLPGVLPRA\", \"RFPLTFGWCF\", \"VYFLQSINF\", \"PTDNYITTY\",\n",
    "    \"ALWEIQQVV\", \"QAKWRLQTL\", \"RTATKQYNV\", \"LLFGYPVYV\"\n",
    "]\n",
    "\n",
    "# --- Category 1: Completely Unseen Pairs ---\n",
    "# Choose percentages for unique TCRs and peptides (start with 2% each)\n",
    "pct_tcr_cat1 = 0.02\n",
    "pct_peptide_cat1 = 0.02\n",
    "\n",
    "unique_tcrs = set(data_for_other_cats['TCR_full'])\n",
    "num_unique_tcrs = len(unique_tcrs)\n",
    "selected_tcrs_cat1 = set(np.random.choice(list(unique_tcrs), size=int(num_unique_tcrs * pct_tcr_cat1), replace=False))\n",
    "\n",
    "# Get all pairs that involve the selected TCRs\n",
    "tcr_pairs = data_for_other_cats[data_for_other_cats['TCR_full'].isin(selected_tcrs_cat1)]\n",
    "# Optionally, remove pairs with peptides we want to keep\n",
    "tcr_pairs = tcr_pairs[~tcr_pairs['Peptide'].isin(peptides_to_keep)]\n",
    "\n",
    "# Derive the set of peptides from these pairs\n",
    "selected_peptides_cat1 = set(tcr_pairs['Peptide'].unique())\n",
    "# Update the TCR set to only those that remain after filtering\n",
    "selected_tcrs_cat1 = set(tcr_pairs['TCR_full'].unique())\n",
    "\n",
    "# Category 1: Define as all pairs where BOTH the TCR is in selected_tcrs_cat1\n",
    "# AND the peptide is in selected_peptides_cat1\n",
    "cat1_df = data_for_other_cats[\n",
    "    data_for_other_cats['TCR_full'].isin(selected_tcrs_cat1) &\n",
    "    data_for_other_cats['Peptide'].isin(selected_peptides_cat1)\n",
    "].copy()\n",
    "cat1_df['test_category'] = 'completely_unseen'\n",
    "cat1_df.loc[cat1_df['TCR_full'].str.startswith('<unk>'), 'test_category'] = 'completely_unseen_unknownalpha'\n",
    "cat1_df.loc[cat1_df['TCR_full'].str.endswith('<unk>'), 'test_category'] = 'completely_unseen_unknownbeta'\n",
    "\n",
    "print(\"Category 1 (completely unseen) pairs:\", len(cat1_df))\n",
    "\n",
    "# Now, to ensure these TCRs and peptides do not appear anywhere in training,\n",
    "# define the training candidate as all rows that do NOT contain any selected TCR or selected peptide.\n",
    "train_candidate = data_for_other_cats[\n",
    "    ~(data_for_other_cats['TCR_full'].isin(selected_tcrs_cat1) | data_for_other_cats['Peptide'].isin(selected_peptides_cat1))\n",
    "]\n",
    "\n",
    "# ------------------------------\n",
    "# --- Category 2: Unseen TCR but Seen Peptide ---\n",
    "# From train_candidate, select a percentage of unique TCRs (e.g., 5%)\n",
    "remaining_unique_tcrs = set(train_candidate['TCR_full'])\n",
    "pct_tcr_cat2 = 0.05\n",
    "selected_tcrs_cat2 = set(np.random.choice(list(remaining_unique_tcrs), size=int(len(remaining_unique_tcrs) * pct_tcr_cat2), replace=False))\n",
    "\n",
    "cat2_df = train_candidate[train_candidate['TCR_full'].isin(selected_tcrs_cat2)].copy()\n",
    "# Add more specific tags for TCRs with unknown regions\n",
    "cat2_df['test_category'] = 'unseen_TCR'\n",
    "cat2_df.loc[cat2_df['TCR_full'].str.startswith('<unk>'), 'test_category'] = 'unseen_TCR_unknownalpha'\n",
    "cat2_df.loc[cat2_df['TCR_full'].str.endswith('<unk>'), 'test_category'] = 'unseen_TCR_unknownbeta'\n",
    "\n",
    "print(\"Category 2 (unseen TCR) pairs:\", len(cat2_df))\n",
    "\n",
    "# Remove Category 2 pairs from train_candidate\n",
    "train_candidate = train_candidate.drop(cat2_df.index)\n",
    "\n",
    "# ------------------------------\n",
    "# --- Category 3: Unseen Peptide but Seen TCR ---\n",
    "# From train_candidate, select a percentage of unique peptides (e.g., 1%)\n",
    "remaining_unique_peptides = set(train_candidate['Peptide'])\n",
    "pct_peptide_cat3 = 0.01\n",
    "selected_peptides_cat3 = set(np.random.choice(list(remaining_unique_peptides), size=int(len(remaining_unique_peptides) * pct_peptide_cat3), replace=False))\n",
    "# Remove any peptides that need to be kept in training from the selected peptides\n",
    "selected_peptides_cat3 = selected_peptides_cat3 - set(peptides_to_keep)\n",
    "\n",
    "cat3_df = train_candidate[train_candidate['Peptide'].isin(selected_peptides_cat3)].copy()\n",
    "\n",
    "cat3_df['test_category'] = 'unseen_peptide'\n",
    "print(\"Category 3 (unseen peptide) pairs:\", len(cat3_df))\n",
    "\n",
    "# Combine all test categories except unseen_HLA\n",
    "other_test_df = pd.concat([cat1_df, cat2_df, cat3_df])\n",
    "other_test_df = other_test_df.drop_duplicates()\n",
    "\n",
    "# Final training set is the remainder of data_for_other_cats that does NOT contain any TCR or peptide selected for Category 1,\n",
    "# AND also does not contain the pairs selected for Categories 2 and 3.\n",
    "final_train_df = train_candidate.drop(cat3_df.index)\n",
    "\n",
    "# Alternatively, if you want to be sure no overlap exists:\n",
    "final_train_df = data_for_other_cats[\n",
    "    ~(data_for_other_cats['TCR_full'].isin(selected_tcrs_cat1) |\n",
    "      data_for_other_cats['Peptide'].isin(selected_peptides_cat1) |\n",
    "      data_for_other_cats['TCR_full'].isin(selected_tcrs_cat2) |\n",
    "      data_for_other_cats['Peptide'].isin(selected_peptides_cat3))\n",
    "]\n",
    "\n",
    "print(f\"\\nFinal Split:\")\n",
    "print(f\"Training set: {len(final_train_df)} pairs ({len(final_train_df) / total_pairs * 100:.2f}%)\")\n",
    "print(f\"Test set (unseen HLA): {len(cat0_df)} pairs ({len(cat0_df) / total_pairs * 100:.2f}%)\")\n",
    "print(f\"Test set (other): {len(other_test_df)} pairs ({len(other_test_df) / total_pairs * 100:.2f}%)\")\n",
    "\n",
    "# Save to three files for correct input\n",
    "cat0_df.to_csv('test_df_unseen_HLA.csv', index=False)\n",
    "other_test_df.to_csv('test_df_other.csv', index=False)\n",
    "final_train_df.to_csv('train_df_other.csv', index=False)\n",
    "\n",
    "# ------------------------------\n",
    "# 4. Test Cases to Validate the Splits\n",
    "# ------------------------------\n",
    "\n",
    "# Create sets from the final training set for lookup\n",
    "train_tcr_set = set(final_train_df['TCR_full'])\n",
    "train_peptide_set = set(final_train_df['Peptide'])\n",
    "\n",
    "print(\"\\nRunning Validation Tests...\")\n",
    "\n",
    "# Test Case 1: Completely Unseen Pairs (Category: 'completely_unseen')\n",
    "cat1 = other_test_df[other_test_df['test_category'] == 'completely_unseen']\n",
    "cat1_tcrs = set(cat1['TCR_full'])\n",
    "cat1_peptides = set(cat1['Peptide'])\n",
    "overlap_tcr_cat1 = cat1_tcrs.intersection(train_tcr_set)\n",
    "overlap_peptides_cat1 = cat1_peptides.intersection(train_peptide_set)\n",
    "\n",
    "print(\"\\nCategory 1: Completely Unseen Pairs\")\n",
    "print(f\"Overlapping TCRs in training: {len(overlap_tcr_cat1)} (should be 0)\")\n",
    "print(f\"Overlapping Peptides in training: {len(overlap_peptides_cat1)} (should be 0)\")\n",
    "assert len(overlap_tcr_cat1) == 0, \"Error: Some TCRs in 'completely_unseen' category are in training!\"\n",
    "assert len(overlap_peptides_cat1) == 0, \"Error: Some peptides in 'completely_unseen' category are in training!\"\n",
    "\n",
    "# Test Case 2: Unseen TCR but Seen Peptide (Category: 'unseen_TCR')\n",
    "cat2 = other_test_df[other_test_df['test_category'] == 'unseen_TCR']\n",
    "cat2_tcrs = set(cat2['TCR_full'])\n",
    "cat2_peptides = set(cat2['Peptide'])\n",
    "overlap_tcr_cat2 = cat2_tcrs.intersection(train_tcr_set)\n",
    "overlap_peptides_cat2 = cat2_peptides.intersection(train_peptide_set)\n",
    "\n",
    "print(\"\\nCategory 2: Unseen TCR but Seen Peptide\")\n",
    "print(f\"Overlapping TCRs in training: {len(overlap_tcr_cat2)} (should be 0)\")\n",
    "print(f\"Overlapping Peptides in training: {len(overlap_peptides_cat2)} (should be > 0)\")\n",
    "assert len(overlap_tcr_cat2) == 0, \"Error: Some TCRs in 'unseen_TCR' category are in training!\"\n",
    "assert len(overlap_peptides_cat2) > 0, \"Error: No peptides in 'unseen_TCR' category are in training!\"\n",
    "\n",
    "# Test Case 3: Unseen Peptide but Seen TCR (Category: 'unseen_peptide')\n",
    "cat3 = other_test_df[other_test_df['test_category'] == 'unseen_peptide']\n",
    "cat3_tcrs = set(cat3['TCR_full'])\n",
    "cat3_peptides = set(cat3['Peptide'])\n",
    "overlap_tcr_cat3 = cat3_tcrs.intersection(train_tcr_set)\n",
    "overlap_peptides_cat3 = cat3_peptides.intersection(train_peptide_set)\n",
    "\n",
    "print(\"\\nCategory 3: Unseen Peptide but Seen TCR\")\n",
    "print(f\"Overlapping TCRs in training: {len(overlap_tcr_cat3)} (should be > 0)\")\n",
    "print(f\"Overlapping Peptides in training: {len(overlap_peptides_cat3)} (should be 0)\")\n",
    "assert len(overlap_peptides_cat3) == 0, \"Error: Some peptides in 'unseen_peptide' category are in training!\"\n",
    "assert len(overlap_tcr_cat3) > 0, \"Error: No TCRs in 'unseen_peptide' category are in training!\"\n",
    "\n",
    "# # Overall Consistency Check: Ensure train + test equals original dataset\n",
    "# We actually don't want to assert this because the\n",
    "# Check this amount of data vs\n",
    "\n",
    "# total_split = len(final_train_df) + len(other_test_df)\n",
    "# assert total_split == len(combined_df), f\"Error: Total split size {total_split} does not equal original dataset size {len(combined_df)}.\"\n",
    "\n",
    "print(\"\\nAll test cases passed. Data split is valid!\")\n",
    "\n",
    "# need to split into three\n",
    "# first one needs to be to train the simple ESM fine tuned model\n",
    "# second one needs to be to train the ESM fine tuned + NC\n",
    "# Third is testing data for both. But do I need to have two separate versions of this\n",
    "# one where the input is just one sequence and the other where the input is two sequences\n",
    "\n",
    "# After final_train_df is defined, stratify it into two sets by promiscuity\n",
    "\n",
    "# Calculate promiscuity for peptides and TCRs\n",
    "peptide_counts = final_train_df.groupby('Peptide')['TCR_full'].nunique()\n",
    "tcr_counts = final_train_df.groupby('TCR_full')['Peptide'].nunique()\n",
    "\n",
    "# Top 10% most promiscuous\n",
    "promiscuous_peptide_thresh = peptide_counts.quantile(0.9)\n",
    "promiscuous_tcr_thresh = tcr_counts.quantile(0.9)\n",
    "promiscuous_peptides = set(peptide_counts[peptide_counts >= promiscuous_peptide_thresh].index)\n",
    "promiscuous_tcrs = set(tcr_counts[tcr_counts >= promiscuous_tcr_thresh].index)\n",
    "\n",
    "# Label each row as promiscuous/non-promiscuous for both TCR and peptide\n",
    "final_train_df['promiscuous_peptide'] = final_train_df['Peptide'].isin(promiscuous_peptides)\n",
    "final_train_df['promiscuous_tcr'] = final_train_df['TCR_full'].isin(promiscuous_tcrs)\n",
    "\n",
    "# Define stratify_label for stratified split\n",
    "final_train_df['stratify_label'] = final_train_df['promiscuous_peptide'].astype(str) + '_' + final_train_df['promiscuous_tcr'].astype(str)\n",
    "\n",
    "# Stratified split: maintain ratio of promiscuous/non-promiscuous in both sets\n",
    "train1_df, train2_df = train_test_split(\n",
    "    final_train_df,\n",
    "    test_size=0.4,\n",
    "    random_state=42,\n",
    "    stratify=final_train_df['stratify_label']\n",
    ")\n",
    "\n",
    "# Save the two training sets\n",
    "train1_df.to_csv('train_df_stratified_1.csv', index=False)\n",
    "train2_df.to_csv('train_df_stratified_2.csv', index=False)\n",
    "\n",
    "# Print summary statistics for validation\n",
    "print(\"\\n--- Training Set 1 Stats ---\")\n",
    "print(f\"Total: {len(train1_df)}\")\n",
    "print(f\"Promiscuous peptides: {train1_df['promiscuous_peptide'].sum()} ({train1_df['promiscuous_peptide'].mean()*100:.2f}%)\")\n",
    "print(f\"Promiscuous TCRs: {train1_df['promiscuous_tcr'].sum()} ({train1_df['promiscuous_tcr'].mean()*100:.2f}%)\")\n",
    "print(f\"Unique peptides: {train1_df['Peptide'].nunique()}\")\n",
    "print(f\"Unique TCRs: {train1_df['TCR_full'].nunique()}\")\n",
    "\n",
    "print(\"\\n--- Training Set 2 Stats ---\")\n",
    "print(f\"Total: {len(train2_df)}\")\n",
    "print(f\"Promiscuous peptides: {train2_df['promiscuous_peptide'].sum()} ({train2_df['promiscuous_peptide'].mean()*100:.2f}%)\")\n",
    "print(f\"Promiscuous TCRs: {train2_df['promiscuous_tcr'].sum()} ({train2_df['promiscuous_tcr'].mean()*100:.2f}%)\")\n",
    "print(f\"Unique peptides: {train2_df['Peptide'].nunique()}\")\n",
    "print(f\"Unique TCRs: {train2_df['TCR_full'].nunique()}\")\n",
    "\n",
    "# Optionally, sample and print distributions\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.hist(train1_df.groupby('TCR_full')['Peptide'].nunique(), bins=30, alpha=0.5, label='Train1: Peptides per TCR')\n",
    "plt.hist(train2_df.groupby('TCR_full')['Peptide'].nunique(), bins=30, alpha=0.5, label='Train2: Peptides per TCR')\n",
    "plt.legend()\n",
    "plt.title('Distribution of Peptides per TCR in Training Sets')\n",
    "plt.savefig('train_peptides_per_tcr_dist.png')\n",
    "\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.hist(train1_df.groupby('Peptide')['TCR_full'].nunique(), bins=30, alpha=0.5, label='Train1: TCRs per Peptide')\n",
    "plt.hist(train2_df.groupby('Peptide')['TCR_full'].nunique(), bins=30, alpha=0.5, label='Train2: TCRs per Peptide')\n",
    "plt.legend()\n",
    "plt.title('Distribution of TCRs per Peptide in Training Sets')\n",
    "plt.savefig('train_tcrs_per_peptide_dist.png')\n",
    "\n",
    "# Save top 10% promiscuous TCRs and peptides to CSV\n",
    "pd.DataFrame({'TCR_full': list(promiscuous_tcrs)}).to_csv('top10pct_promiscuous_tcrs.csv', index=False)\n",
    "pd.DataFrame({'Peptide': list(promiscuous_peptides)}).to_csv('top10pct_promiscuous_peptides.csv', index=False)\n",
    "\n",
    "# Create random pairings for negative examples\n",
    "# First, get the total number of positive examples as a reference\n",
    "# n_positives = len(final_train_df)\n",
    "\n",
    "# # Get unique TCRs and peptides from the original dataset\n",
    "# all_tcrs = final_train_df['TCR_full'].unique()\n",
    "# all_peptides = final_train_df['Peptide'].unique()\n",
    "\n",
    "# # Create random pairs\n",
    "# np.random.seed(42)  # for reproducibility\n",
    "# random_tcrs = np.random.choice(all_tcrs, size=n_positives)\n",
    "# random_peptides = np.random.choice(all_peptides, size=n_positives)\n",
    "\n",
    "# # Create negative dataset\n",
    "# negatives_df = pd.DataFrame({\n",
    "#     'TCR_full': random_tcrs,\n",
    "#     'Peptide': random_peptides\n",
    "# })\n",
    "\n",
    "# # Create a set of positive pairs for filtering\n",
    "# positive_pairs = set(zip(final_train_df['TCR_full'], final_train_df['Peptide']))\n",
    "\n",
    "# # Filter out any accidental positives from the negative dataset\n",
    "# negative_pairs = set(zip(negatives_df['TCR_full'], negatives_df['Peptide']))\n",
    "# true_negatives = negative_pairs - positive_pairs\n",
    "\n",
    "# # Create final negative dataset from the filtered pairs\n",
    "# final_negatives = pd.DataFrame(list(true_negatives), columns=['TCR_full', 'Peptide'])\n",
    "\n",
    "# # Save to CSV\n",
    "# final_negatives.to_csv('train_negatives.csv', index=False)\n",
    "\n",
    "# Load train dataset 1\n",
    "train1_df = pd.read_csv('train_df_stratified_1.csv')\n",
    "\n",
    "# Get unique TCRs and peptides from train1 only\n",
    "train1_tcrs = train1_df['TCR_full'].unique()\n",
    "train1_peptides = train1_df['Peptide'].unique()\n",
    "\n",
    "# Create random pairs using only train1 data\n",
    "n_positives = len(train1_df)\n",
    "np.random.seed(42)  # for reproducibility\n",
    "random_tcrs = np.random.choice(train1_tcrs, size=n_positives)\n",
    "random_peptides = np.random.choice(train1_peptides, size=n_positives)\n",
    "\n",
    "# Create negative dataset\n",
    "negatives_df = pd.DataFrame({\n",
    "    'TCR_full': random_tcrs,\n",
    "    'Peptide': random_peptides\n",
    "})\n",
    "\n",
    "# Create a set of positive pairs for filtering\n",
    "positive_pairs = set(zip(train1_df['TCR_full'], train1_df['Peptide']))\n",
    "\n",
    "# Filter out any accidental positives from the negative dataset\n",
    "negative_pairs = set(zip(negatives_df['TCR_full'], negatives_df['Peptide']))\n",
    "true_negatives = negative_pairs - positive_pairs\n",
    "\n",
    "# Create final negative dataset from the filtered pairs\n",
    "final_negatives = pd.DataFrame(list(true_negatives), columns=['TCR_full', 'Peptide'])\n",
    "\n",
    "# Add binding labels\n",
    "train1_df['Binding'] = 1  # Positive examples\n",
    "final_negatives['Binding'] = 0  # Negative examples\n",
    "\n",
    "# Combine positive and negative examples\n",
    "train_df_full = pd.concat([train1_df, final_negatives])\n",
    "\n",
    "# Save combined dataset\n",
    "train_df_full.to_csv('train_df_stratified_1_full.csv', index=False)\n",
    "\n",
    "\n",
    "# Print summary statistics\n",
    "print(\"\\n--- Negative Dataset Stats ---\")\n",
    "print(f\"Total negative pairs: {len(final_negatives)}\")\n",
    "print(f\"Unique TCRs in negatives: {final_negatives['TCR_full'].nunique()}\")\n",
    "print(f\"Unique peptides in negatives: {final_negatives['Peptide'].nunique()}\")\n",
    "\n",
    "\n",
    "# create negatives for test set for baseline model case\n",
    "\n",
    "# Load your test dataset\n",
    "test_df = pd.read_csv('test_df_other.csv')  # Replace with your actual test dataset filename\n",
    "\n",
    "# Get the number of positive examples in the test dataset\n",
    "n_positives = len(test_df)\n",
    "\n",
    "# Get unique TCRs and peptides from the test dataset\n",
    "all_tcrs = test_df['TCR_full'].unique()\n",
    "all_peptides = test_df['Peptide'].unique()\n",
    "\n",
    "# Create random pairs\n",
    "np.random.seed(42)  # for reproducibility\n",
    "random_tcrs = np.random.choice(all_tcrs, size=n_positives)\n",
    "random_peptides = np.random.choice(all_peptides, size=n_positives)\n",
    "\n",
    "# Create negative dataset\n",
    "negatives_df = pd.DataFrame({\n",
    "    'TCR_full': random_tcrs,\n",
    "    'Peptide': random_peptides\n",
    "})\n",
    "\n",
    "# Create a set of positive pairs for filtering\n",
    "positive_pairs = set(zip(test_df['TCR_full'], test_df['Peptide']))\n",
    "\n",
    "# Filter out any accidental positives from the negative dataset\n",
    "negative_pairs = set(zip(negatives_df['TCR_full'], negatives_df['Peptide']))\n",
    "true_negatives = negative_pairs - positive_pairs\n",
    "\n",
    "# Create final negative dataset and combine with positives for test set\n",
    "test_df['Binding'] = 1  # Add positive labels\n",
    "final_negatives = pd.DataFrame(list(true_negatives), columns=['TCR_full', 'Peptide'])\n",
    "final_negatives['Binding'] = 0  # Add negative labels\n",
    "test_with_negatives = pd.concat([test_df, final_negatives])\n",
    "\n",
    "\n",
    "\n",
    "test_with_negatives.to_csv('test_with_negatives.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f79c48c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tcr-multimodal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
